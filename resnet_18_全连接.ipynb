{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要修改成的数据大小\n",
    "dsize = 128\n",
    "# 最大学习率(优化器)\n",
    "max_lr = 0.012 \n",
    "# 正则项权值的衰减(优化器)\n",
    "weight_decay = 1e-4 \n",
    "# 一般0.9 (优化器)\n",
    "momentum = 0.9 \n",
    "# 最小学习率(退火学习)\n",
    "min_lr = 0.00001\n",
    "# 设置GPU运行\n",
    "device = torch.device('cuda')\n",
    "# 退火学习，下降次数\n",
    "scheduler_step = 40\n",
    "# 打包个数\n",
    "batch_size = 5\n",
    "# 运行批次\n",
    "epoch_Num = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = './competition_data'\n",
    "save_weight_path = src + '/weight'\n",
    "train_image_dir = src + '/train/images'\n",
    "train_mask_dir = src + '/train/masks'\n",
    "test_image_dir = src + '/test/images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = pd.read_csv(src + '/train.csv')\n",
    "fold = (list(range(5))*1000)[:len(depths)] # [0,1,2,3,4,0,1,2...]\n",
    "depths['fold'] = fold # 将数据标记为五份\n",
    "all_ids = depths['id'].values # 取出所有id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片id分为五类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = []\n",
    "for i in range(5):\n",
    "  tem = depths.loc[depths['fold']==i,'id'].values\n",
    "  fold.append(tem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取图片（输入，输出）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_images(ids):\n",
    "  images = []\n",
    "  masks = []\n",
    "  for id in ids:\n",
    "    image = plt.imread(train_image_dir+'/'+id+'.png')[:,:,0:3]\n",
    "    mask = plt.imread(train_mask_dir+'/'+id+'.png')\n",
    "    masks.append(mask)\n",
    "    images.append(image)\n",
    "  return images,masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据集类型\n",
    "数据集类型有三个常用魔法方法\n",
    "1. 初始化（获取参数）\n",
    "2. 获取数据（数据处理，返回数据）\n",
    "3. 获取数据集长度（返回数据集长度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据集\n",
    "class TensorDataset(Dataset):\n",
    "  def __init__(self, data, target):\n",
    "    self.data = data\n",
    "    self.target = target\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # 改变尺寸，并且变为张量\n",
    "    resolved_data = torch.Tensor(\n",
    "      cv2.resize(self.data[index], dsize=(dsize,dsize))\n",
    "    ).reshape(3,dsize,dsize)\n",
    "    # 改变尺寸，并且变为张量\n",
    "    resolved_target = torch.Tensor(\n",
    "      cv2.resize(self.target[index], dsize=(dsize,dsize))\n",
    "    ).reshape(1,dsize,dsize)\n",
    "    # 返回\n",
    "    # (3,128,128),(1,128,128)\n",
    "    return resolved_data,resolved_target\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我的模型(全连接)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encode_model(nn.Module):\n",
    "  def __init__(self,in_channels,out_channels,kernel_size,stride=4,padding=0) -> None:\n",
    "    super().__init__()\n",
    "\n",
    "    self.layer = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=in_channels,out_channels=out_channels,kernel_size=kernel_size,stride=stride,padding=padding),\n",
    "      nn.BatchNorm2d(num_features=out_channels),\n",
    "      nn.ReLU(inplace=True)\n",
    "    )\n",
    "  def forward(self,input):\n",
    "    return self.layer(input)\n",
    "\n",
    "class decode_model(nn.Module):\n",
    "  def __init__(self,in_channels,out_channels,scale) -> None:\n",
    "    super().__init__()\n",
    "\n",
    "    self.layer = nn.Sequential(\n",
    "      nn.ConvTranspose2d(in_channels=in_channels,out_channels=out_channels,kernel_size=scale,stride=scale,padding=0),\n",
    "      nn.ReLU(inplace=True)\n",
    "    )\n",
    "  def forward(self,input):\n",
    "    return self.layer(input)\n",
    "\n",
    "\n",
    "class test_model(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    # 编码\n",
    "    self.layer_0 = encode_model(in_channels=3,out_channels=8,kernel_size=4,stride=4)\n",
    "    self.layer_1 = encode_model(in_channels=8,out_channels=64,kernel_size=3,stride=4)\n",
    "    self.layer_2 = encode_model(in_channels=64,out_channels=128,kernel_size=3,stride=4)\n",
    "    # 全连接\n",
    "    self.layer_3 = nn.Sequential(\n",
    "      nn.Linear(in_features=128*2*2,out_features=256),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Linear(in_features=256,out_features=512),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Linear(in_features=512,out_features=2048),\n",
    "      nn.ReLU(inplace=True)\n",
    "      )\n",
    "    # 解码\n",
    "    self.layer_4 = decode_model(in_channels=512,out_channels=256,scale=4)\n",
    "    self.layer_5 = decode_model(in_channels=256,out_channels=128,scale=4)\n",
    "    self.layer_6 = decode_model(in_channels=128,out_channels=64,scale=4)\n",
    "    # 最后一层\n",
    "    self.layer_7 = nn.Sequential(\n",
    "      nn.Conv2d(64, 32, kernel_size=3, padding=1, bias=False),\n",
    "      nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False),\n",
    "      nn.Conv2d(in_channels=64,out_channels=1,stride=1,kernel_size=1)\n",
    "    )\n",
    "\n",
    "  def forward(self,input):\n",
    "    x0 = self.layer_0(input) # torch.Size([12, 8, 32, 32])\n",
    "    x1 = self.layer_1(x0) # torch.Size([12, 64, 8, 8])\n",
    "    x2 = self.layer_2(x1) # torch.Size([12, 128, 2, 2])\n",
    "\n",
    "    x3 = self.layer_3(x2.reshape(-1,128*2*2)).reshape(-1,512,2,2) # torch.Size([12, 256, 8, 8])\n",
    "\n",
    "    x4 = self.layer_4(x3) # torch.Size([12, 256, 8, 8])\n",
    "    x5 = self.layer_5(x4) # torch.Size([12, 128, 32, 32])\n",
    "    x6 = self.layer_6(x5) # torch.Size([12, 64, 128, 128])\n",
    "    output = self.layer_7(x6)# torch.Size([12, 1, 128, 128])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = torch.Tensor(12,3,128,128)\n",
    "# models = test_model()\n",
    "# outp = models(inp)\n",
    "# outp.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(key):\n",
    "  model = test_model()\n",
    "  model.load_state_dict(torch.load(\"./weight/\" + key+ \".pth\"))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_model(\n",
       "  (layer_0): encode_model(\n",
       "    (layer): Sequential(\n",
       "      (0): Conv2d(3, 8, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_1): encode_model(\n",
       "    (layer): Sequential(\n",
       "      (0): Conv2d(8, 64, kernel_size=(3, 3), stride=(4, 4))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_2): encode_model(\n",
       "    (layer): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(4, 4))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_3): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=2048, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer_4): decode_model(\n",
       "    (layer): Sequential(\n",
       "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_5): decode_model(\n",
       "    (layer): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_6): decode_model(\n",
       "    (layer): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_7): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salt = test_model()\n",
    "# salt = get_model(\"epoch_best\")\n",
    "\n",
    "# GPU 运算\n",
    "salt.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行一次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "def train(loader_data,model):\n",
    "  running_loss = 0\n",
    "  model.train()\n",
    "  for input,mask in loader_data:\n",
    "    input, mask = input.to(device), mask.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()# 梯度初始化为零\n",
    "    # 使用with，会自动关闭梯度计算\n",
    "    # 设置梯度可算\n",
    "    with torch.set_grad_enabled(True):\n",
    "      logit = model(input)# 进行一次计算\n",
    "      loss = nn.BCEWithLogitsLoss()(logit.squeeze(),mask.squeeze())# 计算误差\n",
    "      loss.backward()# 反馈\n",
    "      optimizer.step()# 进行一次参数更新\n",
    "    running_loss += loss.item()*input.size()[0]# 累计平均误差\n",
    "  epoch_loss = running_loss / len(loader_data)# 计算平均误差\n",
    "  return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行一次测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader_test,model):\n",
    "  running_loss = 0.0\n",
    "  data_size = len(loader_test)\n",
    "  # 测试\n",
    "  model.eval()\n",
    "  for input, mask in loader_test:\n",
    "    input, mask = input.to(device), mask.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "      output = model(input)\n",
    "      loss = nn.BCEWithLogitsLoss()(output.squeeze(), mask.squeeze())\n",
    "    running_loss += loss.item() * input.size(0)\n",
    "  return running_loss/data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主函数部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_loss: 283.9057 val_loss: 275.2072  lr: 0.011982\n",
      "epoch: 2 train_loss: 281.6325 val_loss: 275.1507  lr: 0.011926\n",
      "epoch: 3 train_loss: 281.4827 val_loss: 275.8826  lr: 0.011834\n",
      "epoch: 4 train_loss: 281.5008 val_loss: 275.0802  lr: 0.011707\n",
      "epoch: 5 train_loss: 281.6345 val_loss: 275.2994  lr: 0.011544\n",
      "epoch: 6 train_loss: 281.4724 val_loss: 275.5171  lr: 0.011347\n",
      "epoch: 7 train_loss: 281.5463 val_loss: 275.2286  lr: 0.011117\n",
      "epoch: 8 train_loss: 281.4675 val_loss: 275.0744  lr: 0.010855\n",
      "epoch: 9 train_loss: 281.5360 val_loss: 275.4124  lr: 0.010564\n",
      "epoch: 10 train_loss: 281.6531 val_loss: 275.3764  lr: 0.010244\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "  if idx == 1:\n",
    "    break\n",
    "\n",
    "  optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "  lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "  # setdiff1d 取不同的元素\n",
    "  train_id = np.setdiff1d(all_ids, fold[idx])\n",
    "  val_id = fold[idx]\n",
    "  # 取出数据\n",
    "  X_train, y_train = get_train_images(train_id)\n",
    "  X_val, y_val = get_train_images(val_id)\n",
    "  # 制作数据集\n",
    "  train_data = TensorDataset(X_train, y_train)\n",
    "  val_data = TensorDataset(X_val, y_val)\n",
    "  # 打乱，制作可迭代数据集\n",
    "  train_loader = DataLoader(train_data,shuffle=True,batch_size=batch_size) \n",
    "  val_loader = DataLoader(val_data,shuffle=False,batch_size=batch_size) \n",
    "\n",
    "  # num_snapshot = 0\n",
    "  lowest_loss = 10000\n",
    "  # last_train_loss = 0.0\n",
    "# 训练\n",
    "  for epoch_ in range(epoch_Num): # 100\n",
    "    train_loss = train(train_loader, salt)\n",
    "    last_train_loss = train_loss\n",
    "    val_loss = test(val_loader, salt)\n",
    "    # 每训练一次调整学习率（退火学习）\n",
    "    if (epoch_ < scheduler_step-1):\n",
    "      lr_scheduler.step()\n",
    "\n",
    "    #\n",
    "    if epoch_ % 10 == 0:\n",
    "      torch.save(salt.state_dict(), \"./test_weight/\"+ \"epoch_\" + str(epoch_) + '.pth')\n",
    "\n",
    "    if lowest_loss > val_loss:\n",
    "      lowest_loss = val_loss\n",
    "      best_param = salt.state_dict()\n",
    "      torch.save(salt.state_dict(), \"./test_weight/\"+ \"epoch_best\" + '.pth')\n",
    "\n",
    "    # 调节一个\n",
    "    # if (epoch_ + 1) % scheduler_step == 0:\n",
    "      # torch.save(best_param, \"./weight/\" + str(idx) +\"_\"+ str(num_snapshot) + '.pth')\n",
    "      # 重置优化器，以及退火学习\n",
    "      # optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "      # lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "      # num_snapshot += 1\n",
    "      # lowest_loss = 10000\n",
    "\n",
    "    print('epoch: {} train_loss: {:.4f} val_loss: {:.4f}  lr: {:.6f}'.format(epoch_ + 1, train_loss*100, val_loss*100, lr_scheduler.get_last_lr()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = plt.imread(train_image_dir+\"/\" +all_ids[2] + \".png\")\n",
    "\n",
    "# plt.imshow(img,\"./sdfds.png\") 3.9110 3.7660\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 保存参数\n",
    "\n",
    "|操作|函数|\n",
    "|-|-|\n",
    "|保存|torch.save(model.state_dict(),path)|\n",
    "|读取|model.load_state_dict(torch.load(path))|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 保存模型\n",
    "\n",
    "|操作|函数|\n",
    "|-|-|\n",
    "|保存|torch.save(model,path)|\n",
    "|读取|model = torch.load(path)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6e7463ab38ffa65d2678dd98ae9d6c9783a580bfd91baaccc455120c17d4d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
