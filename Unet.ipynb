{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b902261a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbab836c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.13.1-cp310-cp310-macosx_10_9_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch==1.12.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchvision) (1.12.1)\n",
      "Collecting requests\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.2.0-cp310-cp310-macosx_10_10_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchvision) (1.23.3)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchvision) (4.3.0)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Installing collected packages: urllib3, pillow, idna, charset-normalizer, certifi, requests, torchvision\n",
      "\u001b[33m  WARNING: The script normalizer is installed in '/Library/Frameworks/Python.framework/Versions/3.10/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed certifi-2022.9.24 charset-normalizer-2.1.1 idna-3.4 pillow-9.2.0 requests-2.28.1 torchvision-0.13.1 urllib3-1.26.12\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60217c0",
   "metadata": {},
   "source": [
    "## 初始化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d993beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "pad_left = 27\n",
    "pad_right = 27\n",
    "fine_size = 202\n",
    "batch_size = 18\n",
    "epoch = 300 \n",
    "snapshot = 6 \n",
    "max_lr = 0.012 \n",
    "min_lr = 0.001 \n",
    "momentum = 0.9 \n",
    "weight_decay = 1e-4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e3e55b",
   "metadata": {},
   "source": [
    "### GPU运行工具，后面会用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26d0973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b247f80c",
   "metadata": {},
   "source": [
    "### 创建根目录，利用跟目录找到其他目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "535d98a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = f'F:/kaggle/competition_data'\n",
    "save_weight_path = src + '/weight'\n",
    "train_image_dir = src + '/train/images'\n",
    "train_mask_dir = src + '/train/masks'\n",
    "test_image_dir = src + '/test/images'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac086f66",
   "metadata": {},
   "source": [
    "1. 读取depth数据\n",
    "2. 按z的大小排序，替换\n",
    "3. 删除z列，替换\n",
    "4. 分组\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26c5d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = pd.read_csv(src + '/depths.csv')\n",
    "depths.sort_values('z', inplace=True)\n",
    "depths.drop('z', axis=1, inplace=True)\n",
    "depths['fold'] = (list(range(0,5)) * depths.shape[0])[:depths.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ee8485",
   "metadata": {},
   "source": [
    "1. 读取train的数据\n",
    "2. 合并数据\n",
    "3. 创建空数列dist\n",
    "4. 读取图片，灰度图（101，101）\n",
    "5. 计算图片不同像素值个数\n",
    "6. 存入dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b0618d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(src + '/train.csv')\n",
    "train_df = train_df.merge(depths)\n",
    "dist = []\n",
    "\n",
    "for id in train_df.id.values:\n",
    "  img = cv2.imread(train_image_dir+f'/{id}.png', cv2.IMREAD_GRAYSCALE)\n",
    "  dist.append(np.unique(img).shape[0])\n",
    "train_df['unique_pixels'] = dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c09c7",
   "metadata": {},
   "source": [
    "1. 获取id列表\n",
    "2. 根据fold对数据进行分组（5组）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4e79dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_id = train_df['id'].values\n",
    "fold = []\n",
    "for i in range(5):\n",
    "  fold.append(train_df.loc[train_df['fold']==i, 'id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b191b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
