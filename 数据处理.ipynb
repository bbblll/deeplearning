{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要修改成的数据大小\n",
    "dsize = 128\n",
    "# 最大学习率(优化器)\n",
    "max_lr = 0.012 \n",
    "# 正则项权值的衰减(优化器)\n",
    "weight_decay = 1e-4 \n",
    "# 一般0.9 (优化器)\n",
    "momentum = 0.9 \n",
    "# 最小学习率(退火学习)\n",
    "min_lr = 0.001\n",
    "# 设置GPU运行\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = './competition_data'\n",
    "save_weight_path = src + '/weight'\n",
    "train_image_dir = src + '/train/images'\n",
    "train_mask_dir = src + '/train/masks'\n",
    "test_image_dir = src + '/test/images'\n",
    "\n",
    "depths = pd.read_csv(src + '/depths.csv')\n",
    "depths.sort_values('z', inplace=True)\n",
    "depths.drop('z', axis=1, inplace=True)\n",
    "depths['fold'] = (list(range(0,5)) * depths.shape[0])[:depths.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(src + '/train.csv')\n",
    "train_df = train_df.merge(depths)\n",
    "dist = []\n",
    "\n",
    "for id in train_df.id.values:\n",
    "  # f的使用就是将大括号内的变量转为字符\n",
    "  img = plt.imread(train_image_dir+f'/{id}.png')\n",
    "  dist.append(np.unique(img).shape[0])\n",
    "train_df['unique_pixels'] = dist\n",
    "\n",
    "# 图片id\n",
    "all_id = train_df['id'].values\n",
    "# 数据分为5份\n",
    "fold = []\n",
    "for i in range(5):\n",
    "  fold.append(train_df.loc[train_df['fold']==i, 'id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到两数组内的不同值\n",
    "# 数值分成了五份，每一份都能拿来做测试集\n",
    "# 而其他的就是训练集\n",
    "\n",
    "train_id = np.setdiff1d(all_id, fold[0])\n",
    "val_id = fold[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据id获取图片\n",
    "def get_train_images(ids):\n",
    "  images = []\n",
    "  masks = []\n",
    "  for id in ids:\n",
    "    image = plt.imread(train_image_dir+'/'+id+'.png')[0] / 255\n",
    "    mask = plt.imread(train_mask_dir+'/'+id+'.png')[0] / 255\n",
    "    masks.append(mask)\n",
    "    images.append(image)\n",
    "  return images,masks\n",
    "# 获取训练集和验证集\n",
    "train_images,train_masks = get_train_images(train_id)\n",
    "val_images,val_masks = get_train_images(val_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据集类型\n",
    "数据集类型有三个常用魔法方法\n",
    "1. 初始化（获取参数）\n",
    "2. 获取数据（数据处理，返回数据）\n",
    "3. 获取数据集长度（返回数据集长度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据集\n",
    "class TensorDataset(Dataset):\n",
    "  def __init__(self, data, target):\n",
    "    self.data = data\n",
    "    self.target = target\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # 改变尺寸，并且变为张量\n",
    "    resolved_data = torch.Tensor(\n",
    "      cv2.resize(self.data[index], dsize=(dsize,dsize))\n",
    "    ).reshape(1,dsize,dsize)\n",
    "    # 改变尺寸，并且变为张量\n",
    "    resolved_target = torch.Tensor(\n",
    "      cv2.resize(self.target[index], dsize=(dsize,dsize))\n",
    "    ).reshape(1,dsize,dsize)\n",
    "    # 返回\n",
    "    # (1,128,128),(1,128,128)\n",
    "    return resolved_data,resolved_target\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据集对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set = TensorDataset(train_images,train_masks)\n",
    "val_data_set = TensorDataset(val_images,val_masks)\n",
    "\n",
    "# (18,1,128,128)\n",
    "train_loader = DataLoader(\n",
    "  train_data_set,\n",
    "  shuffle=True,\n",
    "  batch_size=18\n",
    ") \n",
    "# (18,1,128,128)\n",
    "val_loader = DataLoader(\n",
    "  val_data_set,\n",
    "  shuffle=False,\n",
    "  batch_size=18\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self,in_size,out_size) -> None:\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.ConvTranspose2d(in_channels=in_size,out_channels=out_size,kernel_size=2,stride=2,padding=0)\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=in_size,out_channels=out_size,stride=1,padding=1,kernel_size=3),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "  def forward(self,x1,x2):\n",
    "    y1 = self.layer1(x1)\n",
    "    tem = torch.cat((y1,x2),dim=1)\n",
    "    y2 = self.layer2(tem)\n",
    "    return y2\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=1,out_channels=4,stride=2,padding=1,kernel_size=3),\n",
    "      nn.BatchNorm2d(num_features=4),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=4,out_channels=8,stride=2,padding=1,kernel_size=3),\n",
    "      nn.BatchNorm2d(num_features=8),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.layer3 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=8,out_channels=16,stride=2,padding=1,kernel_size=3),\n",
    "      nn.BatchNorm2d(num_features=16),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.layer4 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=16,out_channels=32,stride=2,padding=1,kernel_size=3),\n",
    "      nn.BatchNorm2d(num_features=32),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.decoder1 = Decoder(32,16)\n",
    "    self.decoder2 = Decoder(16,8)\n",
    "    self.decoder3 = Decoder(8,4)\n",
    "    self.last = nn.Sequential(\n",
    "      nn.ConvTranspose2d(in_channels=4,out_channels=1,kernel_size=2,stride=2),\n",
    "      nn.Conv2d(in_channels=1,kernel_size=5,out_channels=1,padding=4),\n",
    "      nn.Conv2d(in_channels=1,kernel_size=5,out_channels=1),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "  def forward(self,input):\n",
    "    x1 = self.layer1(input) # torch.Size([18, 4, 64, 64])\n",
    "    x2 = self.layer2(x1) # torch.Size([18, 8, 32, 32])\n",
    "    x3 = self.layer3(x2) # torch.Size([18, 16, 16, 16])\n",
    "    x4 = self.layer4(x3) # torch.Size([18, 32, 8, 8])\n",
    "\n",
    "    y1 = self.decoder1(x4,x3) # torch.Size([18, 16, 16, 16])\n",
    "    y2 = self.decoder2(y1,x2)# torch.Size([18, 8, 32, 32])\n",
    "    y3 = self.decoder3(y2,x1) # torch.Size([18, 4, 64, 64])\n",
    "    output = self.last(y3) # torch.Size([18, 1, 128, 128])\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算误差\n",
    "\n",
    "### 优化器\n",
    "### torch.optim.SGD\n",
    "|参数|类型|描述|\n",
    "|-|-|-|\n",
    "|params|parameters|优化对象的参数|\n",
    "|lr|float|学习率|\n",
    "|momentum|float|一般0.9|\n",
    "|weight_decay|float|正则项权值的衰减系数|\n",
    "\n",
    "### 退火学习\n",
    "### torch.optim.lr_scheduler.CosineAnnealingLR\n",
    "|参数|类型|描述|\n",
    "|-|-|-|\n",
    "|optimizer|optimizer|优化器|\n",
    "|T_max|int|学习率下降到最小值所用周期|\n",
    "|eta_min|float|学习率最小值|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = len(train_loader)\n",
    "running_loss = 0.0\n",
    "\n",
    "salt = SimpleUNet()\n",
    "salt.to(device=device)\n",
    "# 优化器\n",
    "optimizer = torch.optim.SGD(\n",
    "  params = salt.parameters(), # 优化对象\n",
    "  lr=max_lr, # 学习率\n",
    "  momentum=momentum, # 一般0.9\n",
    "  weight_decay=weight_decay# 正则项权值的衰减\n",
    ")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 退火学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "  optimizer=optimizer,# 优化器\n",
    "  T_max=300,# 半个余弦\n",
    "  eta_min=min_lr# 最小学习率\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行一次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要输入数据集，模型\n",
    "# 返回平均损失\n",
    "\n",
    "def train(loader_data,model):\n",
    "  running_loss = 0\n",
    "  model.train()\n",
    "  for input,mask in loader_data:\n",
    "    input, mask = input.to(device), mask.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()# 梯度初始化为零\n",
    "    # 使用with，会自动关闭梯度计算\n",
    "    # 设置梯度可算\n",
    "    with torch.set_grad_enabled(True):\n",
    "      logit = model(input)# 进行一次计算\n",
    "      loss = nn.BCEWithLogitsLoss()(logit.squeeze(),mask.squeeze())# 计算误差\n",
    "      loss.backward()# 反馈\n",
    "      optimizer.step()# 进行一次参数更新\n",
    "    running_loss += loss.item()*input.size()[0]# 累计平均误差\n",
    "  epoch_loss = running_loss / len(loader_data)# 计算平均误差\n",
    "  return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行一次测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader_test,model):\n",
    "  running_loss = 0.0\n",
    "  data_size = len(loader_test)\n",
    "  # 测试\n",
    "  model.eval()\n",
    "  for input, mask in loader_test:\n",
    "    input, mask = input.to(device), mask.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "      output = model(input)\n",
    "      loss = nn.BCEWithLogitsLoss()(output.squeeze(), mask.squeeze())\n",
    "    running_loss += loss.item() * input.size(0)\n",
    "  return running_loss/data_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6e7463ab38ffa65d2678dd98ae9d6c9783a580bfd91baaccc455120c17d4d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
