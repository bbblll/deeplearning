{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要修改成的数据大小\n",
    "dsize = 128\n",
    "# 最大学习率(优化器)\n",
    "max_lr = 0.012 \n",
    "# 正则项权值的衰减(优化器)\n",
    "weight_decay = 1e-4 \n",
    "# 一般0.9 (优化器)\n",
    "momentum = 0.9 \n",
    "# 最小学习率(退火学习)\n",
    "min_lr = 0.001\n",
    "# 设置GPU运行\n",
    "device = torch.device('cuda')\n",
    "# 退火学习，下降次数\n",
    "scheduler_step = 300\n",
    "# 打包个数\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = './competition_data'\n",
    "save_weight_path = src + '/weight'\n",
    "train_image_dir = src + '/train/images'\n",
    "train_mask_dir = src + '/train/masks'\n",
    "test_image_dir = src + '/test/images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取数据id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = pd.read_csv(src + '/train.csv')\n",
    "fold = (list(range(5))*1000)[:len(depths)] # [0,1,2,3,4,0,1,2...]\n",
    "depths['fold'] = fold # 将数据标记为五份\n",
    "all_ids = depths['id'].values # 取出所有id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片id分为五类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = []\n",
    "for i in range(5):\n",
    "  tem = depths.loc[depths['fold']==i,'id'].values\n",
    "  fold.append(tem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取图片（输入，输出）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_images(ids):\n",
    "  images = []\n",
    "  masks = []\n",
    "  for id in ids:\n",
    "    image = plt.imread(train_image_dir+'/'+id+'.png')[0] / 255\n",
    "    mask = plt.imread(train_mask_dir+'/'+id+'.png')[0] / 255\n",
    "    masks.append(mask)\n",
    "    images.append(image)\n",
    "  return images,masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据集类型\n",
    "数据集类型有三个常用魔法方法\n",
    "1. 初始化（获取参数）\n",
    "2. 获取数据（数据处理，返回数据）\n",
    "3. 获取数据集长度（返回数据集长度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据集\n",
    "class TensorDataset(Dataset):\n",
    "  def __init__(self, data, target):\n",
    "    self.data = data\n",
    "    self.target = target\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # 改变尺寸，并且变为张量\n",
    "    resolved_data = torch.Tensor(\n",
    "      cv2.resize(self.data[index], dsize=(dsize,dsize))\n",
    "    ).reshape(1,dsize,dsize)\n",
    "    # 改变尺寸，并且变为张量\n",
    "    resolved_target = torch.Tensor(\n",
    "      cv2.resize(self.target[index], dsize=(dsize,dsize))\n",
    "    ).reshape(1,dsize,dsize)\n",
    "    # 返回\n",
    "    # (1,128,128),(1,128,128)\n",
    "    return resolved_data,resolved_target\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self,in_size,out_size,mid_size,scale) -> None:\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.ConvTranspose2d(in_channels=in_size,out_channels=out_size,kernel_size=scale,stride=scale,padding=0)\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=mid_size,out_channels=out_size,stride=1,padding=1,kernel_size=3),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "  def forward(self,x1,x2):\n",
    "    y1 = self.layer1(x1)\n",
    "    tem = torch.cat((y1,x2),dim=1)\n",
    "    y2 = self.layer2(tem)\n",
    "    return y2\n",
    "\n",
    "class resnet18_model(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    # 定义模型\n",
    "    self.base_model = torchvision.models.resnet18(pretrained = True)\n",
    "    self.base_layers = list(self.base_model.children())\n",
    "    self.input_test = torch.Tensor(12,1,128,128)\n",
    "    self.layer_0 = nn.Conv2d(in_channels=1,out_channels=3,kernel_size=1,stride=1)\n",
    "    self.layer_1 = nn.Sequential(*self.base_layers[0:4])\n",
    "    self.layer_2 = self.base_layers[4]\n",
    "    self.layer_3 = self.base_layers[5]\n",
    "    self.layer_4 = self.base_layers[6]\n",
    "    self.layer_5 = self.base_layers[7]\n",
    "\n",
    "    self.decoder1 = Decoder(512,256,256+256,2)\n",
    "    self.decoder2 = Decoder(256,128,128+128,2)\n",
    "    self.decoder3 = Decoder(128,64,64+64,2)\n",
    "    self.decoder4 = Decoder(64,32,32+64,1)\n",
    "    self.decoder5 = Decoder(32,16,16+3,4)\n",
    "\n",
    "    self.last = nn.Sequential(\n",
    "      nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "      nn.Conv2d(in_channels=16,kernel_size=2,out_channels=8,stride=2),\n",
    "      nn.Conv2d(in_channels=8,kernel_size=1,out_channels=1)\n",
    "    )\n",
    "\n",
    "  def forward(self,input):\n",
    "    x1 = self.layer_0(input)# torch.Size([12, 3, 128, 128])\n",
    "    print(\"x1\",x1.size())\n",
    "    x2 = self.layer_1(x1) # torch.Size([12, 64, 32, 32])\n",
    "    print(\"x2\",x2.size())\n",
    "    x3 = self.layer_2(x2) # torch.Size([12, 64, 32, 32])\n",
    "    print(\"x3\",x3.size())\n",
    "    x4 = self.layer_3(x3) # torch.Size([12, 128, 16, 16])\n",
    "    print(\"x4\",x4.size())\n",
    "    x5 = self.layer_4(x4) # torch.Size([12, 256, 8, 8])\n",
    "    print(\"x5\",x5.size())\n",
    "    x6 = self.layer_5(x5) # torch.Size([12, 512, 4, 4])\n",
    "    print(\"x6\",x6.size())\n",
    "\n",
    "    y1 = self.decoder1(x6,x5) # torch.Size([18, 512, 16, 16])\n",
    "    print(\"y1\",y1.size())\n",
    "    y2 = self.decoder2(y1,x4)# torch.Size([18, 256, 32, 32])\n",
    "    print(\"y2\",y2.size())\n",
    "    y3 = self.decoder3(y2,x3) # torch.Size([18, 128, 64, 64])\n",
    "    print(\"y3\",y3.size())\n",
    "    y4 = self.decoder4(y3,x2) # torch.Size([18, 128, 64, 64])\n",
    "    print(\"y4\",y4.size())\n",
    "    y5 = self.decoder5(y4,x1) # torch.Size([18, 128, 64, 64])\n",
    "    print(\"y5\",y5.size())\n",
    "\n",
    "    output = self.last(y5) # torch.Size([18, 1, 128, 128])\n",
    "    print(\"output\",output.size())\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = torch.Tensor(12,1,128,128)\n",
    "# models = resnet18_model()\n",
    "# outp = models(inp)\n",
    "# outp.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(key):\n",
    "  model = resnet18_model()\n",
    "  model.load_state_dict(torch.load(\"./weight/\" + key+ \".pth\"))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleUNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(8, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(64, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (decoder1): Decoder(\n",
       "    (layer1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder2): Decoder(\n",
       "    (layer1): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder3): Decoder(\n",
       "    (layer1): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(136, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (last): Sequential(\n",
       "    (0): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
       "    (1): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salt = resnet18_model()\n",
    "# salt = get_model(\"0_4\")\n",
    "\n",
    "# GPU 运算\n",
    "salt.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行一次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "def train(loader_data,model):\n",
    "  running_loss = 0\n",
    "  model.train()\n",
    "  for input,mask in loader_data:\n",
    "    input, mask = input.to(device), mask.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()# 梯度初始化为零\n",
    "    # 使用with，会自动关闭梯度计算\n",
    "    # 设置梯度可算\n",
    "    with torch.set_grad_enabled(True):\n",
    "      logit = model(input)# 进行一次计算\n",
    "      loss = nn.BCEWithLogitsLoss()(logit.squeeze(),mask.squeeze())# 计算误差\n",
    "      loss.backward()# 反馈\n",
    "      optimizer.step()# 进行一次参数更新\n",
    "    running_loss += loss.item()*input.size()[0]# 累计平均误差\n",
    "  epoch_loss = running_loss / len(loader_data)# 计算平均误差\n",
    "  return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行一次测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader_test,model):\n",
    "  running_loss = 0.0\n",
    "  data_size = len(loader_test)\n",
    "  # 测试\n",
    "  model.eval()\n",
    "  for input, mask in loader_test:\n",
    "    input, mask = input.to(device), mask.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "      output = model(input)\n",
    "      loss = nn.BCEWithLogitsLoss()(output.squeeze(), mask.squeeze())\n",
    "    running_loss += loss.item() * input.size(0)\n",
    "  return running_loss/data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主函数部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_loss: 11.8775 val_loss: 3.5958  lr: 0.0120\n",
      "epoch: 2 train_loss: 3.7043 val_loss: 3.5617  lr: 0.0120\n",
      "epoch: 3 train_loss: 3.6766 val_loss: 3.5369  lr: 0.0120\n",
      "epoch: 4 train_loss: 3.6577 val_loss: 3.5233  lr: 0.0120\n",
      "epoch: 5 train_loss: 3.6446 val_loss: 3.5182  lr: 0.0120\n",
      "epoch: 6 train_loss: 3.6346 val_loss: 3.5066  lr: 0.0120\n",
      "epoch: 7 train_loss: 3.6258 val_loss: 3.5054  lr: 0.0120\n",
      "epoch: 8 train_loss: 3.6196 val_loss: 3.4944  lr: 0.0120\n",
      "epoch: 9 train_loss: 3.6162 val_loss: 3.4940  lr: 0.0120\n",
      "epoch: 10 train_loss: 3.6134 val_loss: 3.4861  lr: 0.0120\n",
      "epoch: 11 train_loss: 3.6056 val_loss: 3.4809  lr: 0.0120\n",
      "epoch: 12 train_loss: 3.6041 val_loss: 3.4803  lr: 0.0120\n",
      "epoch: 13 train_loss: 3.6019 val_loss: 3.4797  lr: 0.0119\n",
      "epoch: 14 train_loss: 3.5972 val_loss: 3.4756  lr: 0.0119\n",
      "epoch: 15 train_loss: 3.5965 val_loss: 3.4713  lr: 0.0119\n",
      "epoch: 16 train_loss: 3.5950 val_loss: 3.4782  lr: 0.0119\n",
      "epoch: 17 train_loss: 3.5933 val_loss: 3.4664  lr: 0.0119\n",
      "epoch: 18 train_loss: 3.5900 val_loss: 3.4682  lr: 0.0119\n",
      "epoch: 19 train_loss: 3.5886 val_loss: 3.4624  lr: 0.0119\n",
      "epoch: 20 train_loss: 3.5864 val_loss: 3.4617  lr: 0.0119\n",
      "epoch: 21 train_loss: 3.5854 val_loss: 3.4667  lr: 0.0119\n",
      "epoch: 22 train_loss: 3.5850 val_loss: 3.4593  lr: 0.0119\n",
      "epoch: 23 train_loss: 3.5841 val_loss: 3.4620  lr: 0.0118\n",
      "epoch: 24 train_loss: 3.5820 val_loss: 3.4646  lr: 0.0118\n",
      "epoch: 25 train_loss: 3.5825 val_loss: 3.4597  lr: 0.0118\n",
      "epoch: 26 train_loss: 3.5790 val_loss: 3.4556  lr: 0.0118\n",
      "epoch: 27 train_loss: 3.5785 val_loss: 3.4631  lr: 0.0118\n",
      "epoch: 28 train_loss: 3.5773 val_loss: 3.4617  lr: 0.0118\n",
      "epoch: 29 train_loss: 3.5777 val_loss: 3.4522  lr: 0.0117\n",
      "epoch: 30 train_loss: 3.5741 val_loss: 3.4546  lr: 0.0117\n",
      "epoch: 31 train_loss: 3.5738 val_loss: 3.4648  lr: 0.0117\n",
      "epoch: 32 train_loss: 3.5743 val_loss: 3.4500  lr: 0.0117\n",
      "epoch: 33 train_loss: 3.5727 val_loss: 3.4492  lr: 0.0117\n",
      "epoch: 34 train_loss: 3.5739 val_loss: 3.4494  lr: 0.0117\n",
      "epoch: 35 train_loss: 3.5734 val_loss: 3.4511  lr: 0.0116\n",
      "epoch: 36 train_loss: 3.5712 val_loss: 3.4472  lr: 0.0116\n",
      "epoch: 37 train_loss: 3.5694 val_loss: 3.4478  lr: 0.0116\n",
      "epoch: 38 train_loss: 3.5695 val_loss: 3.4504  lr: 0.0116\n",
      "epoch: 39 train_loss: 3.5700 val_loss: 3.4461  lr: 0.0115\n",
      "epoch: 40 train_loss: 3.5693 val_loss: 3.4485  lr: 0.0115\n",
      "epoch: 41 train_loss: 3.5686 val_loss: 3.4432  lr: 0.0115\n",
      "epoch: 42 train_loss: 3.5676 val_loss: 3.4437  lr: 0.0115\n",
      "epoch: 43 train_loss: 3.5673 val_loss: 3.4441  lr: 0.0115\n",
      "epoch: 44 train_loss: 3.5666 val_loss: 3.4445  lr: 0.0114\n",
      "epoch: 45 train_loss: 3.5645 val_loss: 3.4405  lr: 0.0114\n",
      "epoch: 46 train_loss: 3.5634 val_loss: 3.4462  lr: 0.0114\n",
      "epoch: 47 train_loss: 3.5629 val_loss: 3.4407  lr: 0.0113\n",
      "epoch: 48 train_loss: 3.5640 val_loss: 3.4382  lr: 0.0113\n",
      "epoch: 49 train_loss: 3.5634 val_loss: 3.4420  lr: 0.0113\n",
      "epoch: 50 train_loss: 3.5641 val_loss: 3.4419  lr: 0.0113\n",
      "epoch: 51 train_loss: 3.5604 val_loss: 3.4389  lr: 0.0112\n",
      "epoch: 52 train_loss: 3.5617 val_loss: 3.4384  lr: 0.0112\n",
      "epoch: 53 train_loss: 3.5645 val_loss: 3.4467  lr: 0.0112\n",
      "epoch: 54 train_loss: 3.5609 val_loss: 3.4427  lr: 0.0111\n",
      "epoch: 55 train_loss: 3.5596 val_loss: 3.4373  lr: 0.0111\n",
      "epoch: 56 train_loss: 3.5613 val_loss: 3.4375  lr: 0.0111\n",
      "epoch: 57 train_loss: 3.5598 val_loss: 3.4355  lr: 0.0110\n",
      "epoch: 58 train_loss: 3.5616 val_loss: 3.4371  lr: 0.0110\n",
      "epoch: 59 train_loss: 3.5590 val_loss: 3.4351  lr: 0.0110\n",
      "epoch: 60 train_loss: 3.5586 val_loss: 3.4402  lr: 0.0109\n",
      "epoch: 61 train_loss: 3.5612 val_loss: 3.4356  lr: 0.0109\n",
      "epoch: 62 train_loss: 3.5559 val_loss: 3.4419  lr: 0.0109\n",
      "epoch: 63 train_loss: 3.5601 val_loss: 3.4362  lr: 0.0108\n",
      "epoch: 64 train_loss: 3.5596 val_loss: 3.4385  lr: 0.0108\n",
      "epoch: 65 train_loss: 3.5573 val_loss: 3.4343  lr: 0.0108\n",
      "epoch: 66 train_loss: 3.5569 val_loss: 3.4352  lr: 0.0107\n",
      "epoch: 67 train_loss: 3.5588 val_loss: 3.4332  lr: 0.0107\n",
      "epoch: 68 train_loss: 3.5598 val_loss: 3.4329  lr: 0.0107\n",
      "epoch: 69 train_loss: 3.5571 val_loss: 3.4312  lr: 0.0106\n",
      "epoch: 70 train_loss: 3.5582 val_loss: 3.4320  lr: 0.0106\n",
      "epoch: 71 train_loss: 3.5564 val_loss: 3.4323  lr: 0.0105\n",
      "epoch: 72 train_loss: 3.5564 val_loss: 3.4340  lr: 0.0105\n",
      "epoch: 73 train_loss: 3.5562 val_loss: 3.4322  lr: 0.0105\n",
      "epoch: 74 train_loss: 3.5554 val_loss: 3.4327  lr: 0.0104\n",
      "epoch: 75 train_loss: 3.5521 val_loss: 3.4395  lr: 0.0104\n",
      "epoch: 76 train_loss: 3.5576 val_loss: 3.4334  lr: 0.0103\n",
      "epoch: 77 train_loss: 3.5540 val_loss: 3.4351  lr: 0.0103\n",
      "epoch: 78 train_loss: 3.5571 val_loss: 3.4316  lr: 0.0103\n",
      "epoch: 79 train_loss: 3.5561 val_loss: 3.4355  lr: 0.0102\n",
      "epoch: 80 train_loss: 3.5577 val_loss: 3.4340  lr: 0.0102\n",
      "epoch: 81 train_loss: 3.5545 val_loss: 3.4326  lr: 0.0101\n",
      "epoch: 82 train_loss: 3.5560 val_loss: 3.4310  lr: 0.0101\n",
      "epoch: 83 train_loss: 3.5544 val_loss: 3.4290  lr: 0.0101\n",
      "epoch: 84 train_loss: 3.5537 val_loss: 3.4311  lr: 0.0100\n",
      "epoch: 85 train_loss: 3.5540 val_loss: 3.4409  lr: 0.0100\n",
      "epoch: 86 train_loss: 3.5540 val_loss: 3.4365  lr: 0.0099\n",
      "epoch: 87 train_loss: 3.5543 val_loss: 3.4357  lr: 0.0099\n",
      "epoch: 88 train_loss: 3.5524 val_loss: 3.4287  lr: 0.0098\n",
      "epoch: 89 train_loss: 3.5530 val_loss: 3.4274  lr: 0.0098\n",
      "epoch: 90 train_loss: 3.5521 val_loss: 3.4277  lr: 0.0097\n",
      "epoch: 91 train_loss: 3.5542 val_loss: 3.4304  lr: 0.0097\n",
      "epoch: 92 train_loss: 3.5520 val_loss: 3.4310  lr: 0.0096\n",
      "epoch: 93 train_loss: 3.5532 val_loss: 3.4310  lr: 0.0096\n",
      "epoch: 94 train_loss: 3.5522 val_loss: 3.4327  lr: 0.0095\n",
      "epoch: 95 train_loss: 3.5506 val_loss: 3.4310  lr: 0.0095\n",
      "epoch: 96 train_loss: 3.5527 val_loss: 3.4293  lr: 0.0094\n",
      "epoch: 97 train_loss: 3.5530 val_loss: 3.4283  lr: 0.0094\n",
      "epoch: 98 train_loss: 3.5532 val_loss: 3.4264  lr: 0.0093\n",
      "epoch: 99 train_loss: 3.5525 val_loss: 3.4278  lr: 0.0093\n",
      "epoch: 100 train_loss: 3.5518 val_loss: 3.4352  lr: 0.0092\n",
      "epoch: 101 train_loss: 3.5523 val_loss: 3.4269  lr: 0.0092\n",
      "epoch: 102 train_loss: 3.5511 val_loss: 3.4428  lr: 0.0091\n",
      "epoch: 103 train_loss: 3.5515 val_loss: 3.4284  lr: 0.0091\n",
      "epoch: 104 train_loss: 3.5493 val_loss: 3.4279  lr: 0.0090\n",
      "epoch: 105 train_loss: 3.5505 val_loss: 3.4271  lr: 0.0090\n",
      "epoch: 106 train_loss: 3.5498 val_loss: 3.4273  lr: 0.0089\n",
      "epoch: 107 train_loss: 3.5499 val_loss: 3.4268  lr: 0.0089\n",
      "epoch: 108 train_loss: 3.5491 val_loss: 3.4246  lr: 0.0088\n",
      "epoch: 109 train_loss: 3.5512 val_loss: 3.4335  lr: 0.0088\n",
      "epoch: 110 train_loss: 3.5492 val_loss: 3.4273  lr: 0.0087\n",
      "epoch: 111 train_loss: 3.5510 val_loss: 3.4286  lr: 0.0087\n",
      "epoch: 112 train_loss: 3.5509 val_loss: 3.4269  lr: 0.0086\n",
      "epoch: 113 train_loss: 3.5497 val_loss: 3.4217  lr: 0.0086\n",
      "epoch: 114 train_loss: 3.5497 val_loss: 3.4339  lr: 0.0085\n",
      "epoch: 115 train_loss: 3.5504 val_loss: 3.4294  lr: 0.0085\n",
      "epoch: 116 train_loss: 3.5475 val_loss: 3.4224  lr: 0.0084\n",
      "epoch: 117 train_loss: 3.5499 val_loss: 3.4262  lr: 0.0084\n",
      "epoch: 118 train_loss: 3.5472 val_loss: 3.4223  lr: 0.0083\n",
      "epoch: 119 train_loss: 3.5484 val_loss: 3.4228  lr: 0.0083\n",
      "epoch: 120 train_loss: 3.5485 val_loss: 3.4219  lr: 0.0082\n",
      "epoch: 121 train_loss: 3.5484 val_loss: 3.4210  lr: 0.0081\n",
      "epoch: 122 train_loss: 3.5473 val_loss: 3.4320  lr: 0.0081\n",
      "epoch: 123 train_loss: 3.5500 val_loss: 3.4248  lr: 0.0080\n",
      "epoch: 124 train_loss: 3.5465 val_loss: 3.4202  lr: 0.0080\n",
      "epoch: 125 train_loss: 3.5470 val_loss: 3.4240  lr: 0.0079\n",
      "epoch: 126 train_loss: 3.5460 val_loss: 3.4253  lr: 0.0079\n",
      "epoch: 127 train_loss: 3.5455 val_loss: 3.4221  lr: 0.0078\n",
      "epoch: 128 train_loss: 3.5462 val_loss: 3.4304  lr: 0.0078\n",
      "epoch: 129 train_loss: 3.5463 val_loss: 3.4273  lr: 0.0077\n",
      "epoch: 130 train_loss: 3.5436 val_loss: 3.4251  lr: 0.0076\n",
      "epoch: 131 train_loss: 3.5455 val_loss: 3.4197  lr: 0.0076\n",
      "epoch: 132 train_loss: 3.5476 val_loss: 3.4211  lr: 0.0075\n",
      "epoch: 133 train_loss: 3.5440 val_loss: 3.4193  lr: 0.0075\n",
      "epoch: 134 train_loss: 3.5426 val_loss: 3.4190  lr: 0.0074\n",
      "epoch: 135 train_loss: 3.5454 val_loss: 3.4229  lr: 0.0074\n",
      "epoch: 136 train_loss: 3.5449 val_loss: 3.4168  lr: 0.0073\n",
      "epoch: 137 train_loss: 3.5477 val_loss: 3.4177  lr: 0.0072\n",
      "epoch: 138 train_loss: 3.5422 val_loss: 3.4182  lr: 0.0072\n",
      "epoch: 139 train_loss: 3.5461 val_loss: 3.4193  lr: 0.0071\n",
      "epoch: 140 train_loss: 3.5433 val_loss: 3.4184  lr: 0.0071\n",
      "epoch: 141 train_loss: 3.5438 val_loss: 3.4266  lr: 0.0070\n",
      "epoch: 142 train_loss: 3.5438 val_loss: 3.4173  lr: 0.0070\n",
      "epoch: 143 train_loss: 3.5435 val_loss: 3.4155  lr: 0.0069\n",
      "epoch: 144 train_loss: 3.5456 val_loss: 3.4174  lr: 0.0068\n",
      "epoch: 145 train_loss: 3.5444 val_loss: 3.4167  lr: 0.0068\n",
      "epoch: 146 train_loss: 3.5405 val_loss: 3.4236  lr: 0.0067\n",
      "epoch: 147 train_loss: 3.5423 val_loss: 3.4197  lr: 0.0067\n",
      "epoch: 148 train_loss: 3.5436 val_loss: 3.4224  lr: 0.0066\n",
      "epoch: 149 train_loss: 3.5414 val_loss: 3.4192  lr: 0.0066\n",
      "epoch: 150 train_loss: 3.5411 val_loss: 3.4150  lr: 0.0065\n",
      "epoch: 151 train_loss: 3.5408 val_loss: 3.4185  lr: 0.0064\n",
      "epoch: 152 train_loss: 3.5418 val_loss: 3.4265  lr: 0.0064\n",
      "epoch: 153 train_loss: 3.5426 val_loss: 3.4165  lr: 0.0063\n",
      "epoch: 154 train_loss: 3.5413 val_loss: 3.4168  lr: 0.0063\n",
      "epoch: 155 train_loss: 3.5422 val_loss: 3.4120  lr: 0.0062\n",
      "epoch: 156 train_loss: 3.5391 val_loss: 3.4159  lr: 0.0062\n",
      "epoch: 157 train_loss: 3.5400 val_loss: 3.4192  lr: 0.0061\n",
      "epoch: 158 train_loss: 3.5382 val_loss: 3.4164  lr: 0.0060\n",
      "epoch: 159 train_loss: 3.5394 val_loss: 3.4245  lr: 0.0060\n",
      "epoch: 160 train_loss: 3.5377 val_loss: 3.4122  lr: 0.0059\n",
      "epoch: 161 train_loss: 3.5385 val_loss: 3.4144  lr: 0.0059\n",
      "epoch: 162 train_loss: 3.5404 val_loss: 3.4144  lr: 0.0058\n",
      "epoch: 163 train_loss: 3.5405 val_loss: 3.4165  lr: 0.0058\n",
      "epoch: 164 train_loss: 3.5376 val_loss: 3.4136  lr: 0.0057\n",
      "epoch: 165 train_loss: 3.5380 val_loss: 3.4158  lr: 0.0056\n",
      "epoch: 166 train_loss: 3.5347 val_loss: 3.4109  lr: 0.0056\n",
      "epoch: 167 train_loss: 3.5371 val_loss: 3.4114  lr: 0.0055\n",
      "epoch: 168 train_loss: 3.5366 val_loss: 3.4150  lr: 0.0055\n",
      "epoch: 169 train_loss: 3.5361 val_loss: 3.4171  lr: 0.0054\n",
      "epoch: 170 train_loss: 3.5379 val_loss: 3.4136  lr: 0.0054\n",
      "epoch: 171 train_loss: 3.5379 val_loss: 3.4124  lr: 0.0053\n",
      "epoch: 172 train_loss: 3.5361 val_loss: 3.4089  lr: 0.0052\n",
      "epoch: 173 train_loss: 3.5353 val_loss: 3.4107  lr: 0.0052\n",
      "epoch: 174 train_loss: 3.5368 val_loss: 3.4102  lr: 0.0051\n",
      "epoch: 175 train_loss: 3.5347 val_loss: 3.4092  lr: 0.0051\n",
      "epoch: 176 train_loss: 3.5346 val_loss: 3.4055  lr: 0.0050\n",
      "epoch: 177 train_loss: 3.5346 val_loss: 3.4057  lr: 0.0050\n",
      "epoch: 178 train_loss: 3.5337 val_loss: 3.4091  lr: 0.0049\n",
      "epoch: 179 train_loss: 3.5331 val_loss: 3.4065  lr: 0.0049\n",
      "epoch: 180 train_loss: 3.5334 val_loss: 3.4075  lr: 0.0048\n",
      "epoch: 181 train_loss: 3.5303 val_loss: 3.4073  lr: 0.0047\n",
      "epoch: 182 train_loss: 3.5316 val_loss: 3.4104  lr: 0.0047\n",
      "epoch: 183 train_loss: 3.5353 val_loss: 3.4120  lr: 0.0046\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\YOUR_M~1\\AppData\\Local\\Temp/ipykernel_8452/2644048621.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# 训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mepoch_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 300\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msalt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msalt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# 每训练一次调整学习率（退火学习）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\YOUR_M~1\\AppData\\Local\\Temp/ipykernel_8452/2065580904.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(loader_data, model)\u001b[0m\n\u001b[0;32m     16\u001b[0m       \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# 反馈\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# 进行一次参数更新\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m# 累计平均误差\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m   \u001b[0mepoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# 计算平均误差\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "  if idx == 1:\n",
    "    break\n",
    "\n",
    "  optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "  lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "  # setdiff1d 取不同的元素\n",
    "  train_id = np.setdiff1d(all_ids, fold[idx])\n",
    "  val_id = fold[idx]\n",
    "  # 取出数据\n",
    "  X_train, y_train = get_train_images(train_id)\n",
    "  X_val, y_val = get_train_images(val_id)\n",
    "  # 制作数据集\n",
    "  train_data = TensorDataset(X_train, y_train)\n",
    "  val_data = TensorDataset(X_val, y_val)\n",
    "  # 打乱，制作可迭代数据集\n",
    "  train_loader = DataLoader(train_data,shuffle=True,batch_size=batch_size) \n",
    "  val_loader = DataLoader(val_data,shuffle=False,batch_size=batch_size) \n",
    "\n",
    "  num_snapshot = 0\n",
    "  lowest_loss = 10000\n",
    "# 训练\n",
    "  for epoch_ in range(300): # 300\n",
    "    train_loss = train(train_loader, salt)\n",
    "    val_loss = test(val_loader, salt)\n",
    "    # 每训练一次调整学习率（退火学习）\n",
    "    lr_scheduler.step()\n",
    "    if epoch_ % 5 == 0:\n",
    "      torch.save(salt.state_dict(), \"./weight/\"+ \"epoch_\" + str(epoch_) + '.pth')\n",
    "\n",
    "    # if lowest_loss > val_loss:\n",
    "    #   lowest_loss = val_loss\n",
    "    #   best_param = salt.state_dict()\n",
    "\n",
    "    # 调节一个\n",
    "    if (epoch_ + 1) % scheduler_step == 0:\n",
    "      # torch.save(best_param, \"./weight/\" + str(idx) +\"_\"+ str(num_snapshot) + '.pth')\n",
    "      # 重置优化器，以及退火学习\n",
    "      optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "      lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "      num_snapshot += 1\n",
    "      lowest_loss = 10000\n",
    "\n",
    "    print('epoch: {} train_loss: {:.4f} val_loss: {:.4f}  lr: {:.4f}'.format(epoch_ + 1, train_loss*100, val_loss*100, lr_scheduler.get_last_lr()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 保存参数\n",
    "\n",
    "|操作|函数|\n",
    "|-|-|\n",
    "|保存|torch.save(model.state_dict(),path)|\n",
    "|读取|model.load_state_dict(torch.load(path))|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 保存模型\n",
    "\n",
    "|操作|函数|\n",
    "|-|-|\n",
    "|保存|torch.save(model,path)|\n",
    "|读取|model = torch.load(path)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6e7463ab38ffa65d2678dd98ae9d6c9783a580bfd91baaccc455120c17d4d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
