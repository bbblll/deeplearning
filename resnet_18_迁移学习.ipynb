{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要修改成的数据大小\n",
    "dsize = 128\n",
    "# 最大学习率(优化器)\n",
    "max_lr = 0.00008 \n",
    "# 正则项权值的衰减(优化器)\n",
    "weight_decay = 1e-4 \n",
    "# 一般0.9 (优化器)\n",
    "momentum = 0.9 \n",
    "# 最小学习率(退火学习)\n",
    "min_lr = 0.000001\n",
    "# 设置GPU运行\n",
    "device = torch.device('cuda')\n",
    "# 退火学习，下降次数\n",
    "scheduler_step = 20\n",
    "# 打包个数\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = './competition_data'\n",
    "save_weight_path = src + '/weight'\n",
    "train_image_dir = src + '/train/images'\n",
    "train_mask_dir = src + '/train/masks'\n",
    "test_image_dir = src + '/test/images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = pd.read_csv(src + '/train.csv')\n",
    "fold = (list(range(5))*1000)[:len(depths)] # [0,1,2,3,4,0,1,2...]\n",
    "depths['fold'] = fold # 将数据标记为五份\n",
    "all_ids = depths['id'].values # 取出所有id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片id分为五类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = []\n",
    "for i in range(5):\n",
    "  tem = depths.loc[depths['fold']==i,'id'].values\n",
    "  fold.append(tem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取图片（输入，输出）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_images(ids):\n",
    "  images = []\n",
    "  masks = []\n",
    "  for id in ids:\n",
    "    image = plt.imread(train_image_dir+'/'+id+'.png')[0] / 255\n",
    "    mask = plt.imread(train_mask_dir+'/'+id+'.png')[0] / 255\n",
    "    masks.append(mask)\n",
    "    images.append(image)\n",
    "  return images,masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据集类型\n",
    "数据集类型有三个常用魔法方法\n",
    "1. 初始化（获取参数）\n",
    "2. 获取数据（数据处理，返回数据）\n",
    "3. 获取数据集长度（返回数据集长度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据集\n",
    "class TensorDataset(Dataset):\n",
    "  def __init__(self, data, target):\n",
    "    self.data = data\n",
    "    self.target = target\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # 改变尺寸，并且变为张量\n",
    "    resolved_data = torch.Tensor(\n",
    "      cv2.resize(self.data[index], dsize=(dsize,dsize))\n",
    "    ).reshape(1,dsize,dsize)\n",
    "    # 改变尺寸，并且变为张量\n",
    "    resolved_target = torch.Tensor(\n",
    "      cv2.resize(self.target[index], dsize=(dsize,dsize))\n",
    "    ).reshape(1,dsize,dsize)\n",
    "    # 返回\n",
    "    # (1,128,128),(1,128,128)\n",
    "    return resolved_data,resolved_target\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我的模型(resnet 迁移学习)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self,in_size,out_size,mid_size,scale) -> None:\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.ConvTranspose2d(in_channels=in_size,out_channels=out_size,kernel_size=scale,stride=scale,padding=0)\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=mid_size,out_channels=out_size,stride=1,padding=1,kernel_size=3),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "  def forward(self,x1,x2):\n",
    "    y1 = self.layer1(x1)\n",
    "    tem = torch.cat((y1,x2),dim=1)\n",
    "    y2 = self.layer2(tem)\n",
    "    return y2\n",
    "\n",
    "class resnet18_model(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    # 定义模型\n",
    "    self.base_model = torchvision.models.resnet18(pretrained = True)\n",
    "    self.base_layers = list(self.base_model.children())\n",
    "    self.input_test = torch.Tensor(12,1,128,128)\n",
    "    self.layer_0 = nn.Conv2d(in_channels=1,out_channels=3,kernel_size=1,stride=1)\n",
    "    self.layer_1 = nn.Sequential(*self.base_layers[0:4])\n",
    "    self.layer_2 = self.base_layers[4]\n",
    "    self.layer_3 = self.base_layers[5]\n",
    "    self.layer_4 = self.base_layers[6]\n",
    "    self.layer_5 = self.base_layers[7]\n",
    "\n",
    "    self.decoder1 = Decoder(512,256,256+128,4)\n",
    "    self.decoder2 = Decoder(256,128,128+64,2)\n",
    "    self.decoder3 = Decoder(128,64,64+3,4)\n",
    "\n",
    "\n",
    "    self.last = nn.Conv2d(in_channels=64,kernel_size=1,out_channels=1)\n",
    "\n",
    "  def forward(self,input):\n",
    "    x1 = self.layer_0(input)# torch.Size([12, 3, 128, 128])\n",
    "\n",
    "    x2 = self.layer_1(x1) # torch.Size([12, 64, 32, 32])\n",
    "    x3 = self.layer_2(x2) # torch.Size([12, 64, 32, 32])\n",
    "    x4 = self.layer_3(x3) # torch.Size([12, 128, 16, 16])\n",
    "    x5 = self.layer_4(x4) # torch.Size([12, 256, 8, 8])\n",
    "    x6 = self.layer_5(x5) # torch.Size([12, 512, 4, 4])\n",
    "\n",
    "    y1 = self.decoder1(x6,x4) # torch.Size([12, 256, 16, 16])\n",
    "    y2 = self.decoder2(y1,x2) # torch.Size([12, 128, 32, 32])\n",
    "    y3 = self.decoder3(y2,x1) # torch.Size([12, 64, 128, 128])\n",
    "\n",
    "    output = self.last(y3)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = torch.Tensor(12,1,128,128)\n",
    "# models = resnet18_model()\n",
    "# outp = models(inp)\n",
    "# outp.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(key):\n",
    "  model = resnet18_model()\n",
    "  model.load_state_dict(torch.load(\"./weight/\" + key+ \".pth\"))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\your_master\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\your_master\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "resnet18_model(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (layer_0): Conv2d(1, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (layer_1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer_2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder1): Decoder(\n",
       "    (layer1): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder2): Decoder(\n",
       "    (layer1): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder3): Decoder(\n",
       "    (layer1): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(67, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (last): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# salt = resnet18_model()\n",
    "salt = get_model(\"epoch_best\")\n",
    "\n",
    "# GPU 运算\n",
    "salt.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行一次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "def train(loader_data,model):\n",
    "  running_loss = 0\n",
    "  model.train()\n",
    "  for input,mask in loader_data:\n",
    "    input, mask = input.to(device), mask.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()# 梯度初始化为零\n",
    "    # 使用with，会自动关闭梯度计算\n",
    "    # 设置梯度可算\n",
    "    with torch.set_grad_enabled(True):\n",
    "      logit = model(input)# 进行一次计算\n",
    "      loss = nn.BCEWithLogitsLoss()(logit.squeeze(),mask.squeeze())# 计算误差\n",
    "      loss.backward()# 反馈\n",
    "      optimizer.step()# 进行一次参数更新\n",
    "    running_loss += loss.item()*input.size()[0]# 累计平均误差\n",
    "  epoch_loss = running_loss / len(loader_data)# 计算平均误差\n",
    "  return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行一次测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader_test,model):\n",
    "  running_loss = 0.0\n",
    "  data_size = len(loader_test)\n",
    "  # 测试\n",
    "  model.eval()\n",
    "  for input, mask in loader_test:\n",
    "    input, mask = input.to(device), mask.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "      output = model(input)\n",
    "      loss = nn.BCEWithLogitsLoss()(output.squeeze(), mask.squeeze())\n",
    "    running_loss += loss.item() * input.size(0)\n",
    "  return running_loss/data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主函数部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_loss: 3.8258 val_loss: 3.7119  lr: 0.000080\n",
      "epoch: 2 train_loss: 3.8086 val_loss: 3.6951  lr: 0.000087\n",
      "epoch: 3 train_loss: 3.7926 val_loss: 3.6788  lr: 0.000096\n",
      "epoch: 4 train_loss: 3.7770 val_loss: 3.6627  lr: 0.000106\n",
      "epoch: 5 train_loss: 3.7618 val_loss: 3.6472  lr: 0.000116\n",
      "epoch: 6 train_loss: 3.7471 val_loss: 3.6323  lr: 0.000128\n",
      "epoch: 7 train_loss: 3.7332 val_loss: 3.6181  lr: 0.000141\n",
      "epoch: 8 train_loss: 3.7200 val_loss: 3.6047  lr: 0.000155\n",
      "epoch: 9 train_loss: 3.7077 val_loss: 3.5922  lr: 0.000170\n",
      "epoch: 10 train_loss: 3.6963 val_loss: 3.5807  lr: 0.000187\n",
      "epoch: 11 train_loss: 3.6860 val_loss: 3.5702  lr: 0.000206\n",
      "epoch: 12 train_loss: 3.6766 val_loss: 3.5607  lr: 0.000227\n",
      "epoch: 13 train_loss: 3.6682 val_loss: 3.5522  lr: 0.000250\n",
      "epoch: 14 train_loss: 3.6609 val_loss: 3.5447  lr: 0.000275\n",
      "epoch: 15 train_loss: 3.6546 val_loss: 3.5384  lr: 0.000302\n",
      "epoch: 16 train_loss: 3.6492 val_loss: 3.5329  lr: 0.000332\n",
      "epoch: 17 train_loss: 3.6448 val_loss: 3.5283  lr: 0.000365\n",
      "epoch: 18 train_loss: 3.6411 val_loss: 3.5244  lr: 0.000402\n",
      "epoch: 19 train_loss: 3.6381 val_loss: 3.5213  lr: 0.000442\n",
      "epoch: 20 train_loss: 3.6358 val_loss: 3.5188  lr: 0.000486\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "  if idx == 1:\n",
    "    break\n",
    "\n",
    "  optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "  lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "  # setdiff1d 取不同的元素\n",
    "  train_id = np.setdiff1d(all_ids, fold[idx])\n",
    "  val_id = fold[idx]\n",
    "  # 取出数据\n",
    "  X_train, y_train = get_train_images(train_id)\n",
    "  X_val, y_val = get_train_images(val_id)\n",
    "  # 制作数据集\n",
    "  train_data = TensorDataset(X_train, y_train)\n",
    "  val_data = TensorDataset(X_val, y_val)\n",
    "  # 打乱，制作可迭代数据集\n",
    "  train_loader = DataLoader(train_data,shuffle=True,batch_size=batch_size) \n",
    "  val_loader = DataLoader(val_data,shuffle=False,batch_size=batch_size) \n",
    "\n",
    "  # num_snapshot = 0\n",
    "  lr_step = 0\n",
    "  lowest_loss = 10000\n",
    "  last_train_loss = 0.0\n",
    "# 训练\n",
    "  for epoch_ in range(scheduler_step): # 300\n",
    "    lr_step = lr_step + 1\n",
    "    train_loss = train(train_loader, salt)\n",
    "    if last_train_loss != 0:\n",
    "      if abs(train_loss - last_train_loss)/train_loss <0.03:\n",
    "        max_lr = 1.1*lr_scheduler.get_last_lr()[0]\n",
    "        optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "        lr_step = 0\n",
    "    last_train_loss = train_loss\n",
    "    val_loss = test(val_loader, salt)\n",
    "    # 每训练一次调整学习率（退火学习）\n",
    "    if (lr_step < scheduler_step-1)&(lr_step!=0):\n",
    "      lr_scheduler.step()\n",
    "\n",
    "    #\n",
    "    if epoch_ % 10 == 0:\n",
    "      torch.save(salt.state_dict(), \"./weight/\"+ \"epoch_\" + str(epoch_) + '.pth')\n",
    "\n",
    "    if lowest_loss > val_loss:\n",
    "      lowest_loss = val_loss\n",
    "      best_param = salt.state_dict()\n",
    "      torch.save(salt.state_dict(), \"./weight/\"+ \"epoch_best_\" + '.pth')\n",
    "\n",
    "    # 调节一个\n",
    "    # if (epoch_ + 1) % scheduler_step == 0:\n",
    "      # torch.save(best_param, \"./weight/\" + str(idx) +\"_\"+ str(num_snapshot) + '.pth')\n",
    "      # 重置优化器，以及退火学习\n",
    "      # optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "      # lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "      # num_snapshot += 1\n",
    "      # lowest_loss = 10000\n",
    "\n",
    "    print('epoch: {} train_loss: {:.4f} val_loss: {:.4f}  lr: {:.6f}'.format(epoch_ + 1, train_loss*100, val_loss*100, lr_scheduler.get_last_lr()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "img = plt.imread(train_image_dir+\"/\" +all_ids[2] + \".png\")\n",
    "\n",
    "plt.imshow(img,\"./sdfds.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 保存参数\n",
    "\n",
    "|操作|函数|\n",
    "|-|-|\n",
    "|保存|torch.save(model.state_dict(),path)|\n",
    "|读取|model.load_state_dict(torch.load(path))|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 保存模型\n",
    "\n",
    "|操作|函数|\n",
    "|-|-|\n",
    "|保存|torch.save(model,path)|\n",
    "|读取|model = torch.load(path)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6e7463ab38ffa65d2678dd98ae9d6c9783a580bfd91baaccc455120c17d4d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
