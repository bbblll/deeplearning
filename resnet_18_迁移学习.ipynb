{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要修改成的数据大小\n",
    "dsize = 128\n",
    "# 最大学习率(优化器)\n",
    "max_lr = 0.012 \n",
    "# 正则项权值的衰减(优化器)\n",
    "weight_decay = 1e-4 \n",
    "# 一般0.9 (优化器)\n",
    "momentum = 0.9 \n",
    "# 最小学习率(退火学习)\n",
    "min_lr = 0.00001\n",
    "# 设置GPU运行\n",
    "device = torch.device('cuda')\n",
    "# 退火学习，下降次数\n",
    "scheduler_step = 40\n",
    "# 打包个数\n",
    "batch_size = 5\n",
    "# 运行批次\n",
    "epoch_Num = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = './competition_data'\n",
    "save_weight_path = src + '/weight'\n",
    "train_image_dir = src + '/train/images'\n",
    "train_mask_dir = src + '/train/masks'\n",
    "test_image_dir = src + '/test/images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = pd.read_csv(src + '/train.csv')\n",
    "fold = (list(range(5))*1000)[:len(depths)] # [0,1,2,3,4,0,1,2...]\n",
    "depths['fold'] = fold # 将数据标记为五份\n",
    "all_ids = depths['id'].values # 取出所有id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片id分为五类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = []\n",
    "for i in range(5):\n",
    "  tem = depths.loc[depths['fold']==i,'id'].values\n",
    "  fold.append(tem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取图片（输入，输出）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_images(ids):\n",
    "  images = []\n",
    "  masks = []\n",
    "  for id in ids:\n",
    "    image = plt.imread(train_image_dir+'/'+id+'.png')[:,:,0:3]\n",
    "    mask = plt.imread(train_mask_dir+'/'+id+'.png')\n",
    "    masks.append(mask)\n",
    "    images.append(image)\n",
    "  return images,masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据集类型\n",
    "数据集类型有三个常用魔法方法\n",
    "1. 初始化（获取参数）\n",
    "2. 获取数据（数据处理，返回数据）\n",
    "3. 获取数据集长度（返回数据集长度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据集\n",
    "class TensorDataset(Dataset):\n",
    "  def __init__(self, data, target):\n",
    "    self.data = data\n",
    "    self.target = target\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # 改变尺寸，并且变为张量\n",
    "    resolved_data = torch.Tensor(\n",
    "      cv2.resize(self.data[index], dsize=(dsize,dsize))\n",
    "    ).reshape(3,dsize,dsize)\n",
    "    # 改变尺寸，并且变为张量\n",
    "    resolved_target = torch.Tensor(\n",
    "      cv2.resize(self.target[index], dsize=(dsize,dsize))\n",
    "    ).reshape(1,dsize,dsize)\n",
    "    # 返回\n",
    "    # (3,128,128),(1,128,128)\n",
    "    return resolved_data,resolved_target\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我的模型(resnet 迁移学习)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self,in_size,out_size,mid_size,scale) -> None:\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.ConvTranspose2d(in_channels=in_size,out_channels=out_size,kernel_size=scale,stride=scale,padding=0)\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=mid_size,out_channels=out_size,stride=1,padding=1,kernel_size=3),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "  def forward(self,x1,x2):\n",
    "    y1 = self.layer1(x1)\n",
    "    tem = torch.cat((y1,x2),dim=1)\n",
    "    y2 = self.layer2(tem)\n",
    "    return y2\n",
    "\n",
    "class resnet18_model(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    # 定义模型\n",
    "    self.base_model = torchvision.models.resnet18(pretrained = True)\n",
    "    self.base_layers = list(self.base_model.children())\n",
    "    self.input_test = torch.Tensor(12,1,128,128)\n",
    "    self.layer_0 = nn.Conv2d(in_channels=1,out_channels=3,kernel_size=1,stride=1)\n",
    "    self.layer_1 = nn.Sequential(*self.base_layers[0:4])\n",
    "    self.layer_2 = self.base_layers[4]\n",
    "    self.layer_3 = self.base_layers[5]\n",
    "    self.layer_4 = self.base_layers[6]\n",
    "    self.layer_5 = self.base_layers[7]\n",
    "\n",
    "    self.decoder1 = Decoder(512,256,256+128,4)\n",
    "    self.decoder2 = Decoder(256,128,128+64,2)\n",
    "    self.decoder3 = Decoder(128,64,64+3,4)\n",
    "\n",
    "    self.layer_6 = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3,padding=2)\n",
    "    self.layer_7 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3)\n",
    "\n",
    "\n",
    "    self.last = nn.Conv2d(in_channels=64,kernel_size=1,out_channels=1)\n",
    "\n",
    "  def forward(self,input):\n",
    "    # x1 = self.layer_0(input)# torch.Size([12, 3, 128, 128])\n",
    "\n",
    "    x1 = self.layer_1(input) # torch.Size([12, 64, 32, 32])\n",
    "    x2 = self.layer_2(x1) # torch.Size([12, 64, 32, 32])\n",
    "    x3 = self.layer_3(x2) # torch.Size([12, 128, 16, 16])\n",
    "    x4 = self.layer_4(x3) # torch.Size([12, 256, 8, 8])\n",
    "    x5 = self.layer_5(x4) # torch.Size([12, 512, 4, 4])\n",
    "\n",
    "    y1 = self.decoder1(x5,x3) # torch.Size([12, 256, 16, 16])\n",
    "    y2 = self.decoder2(y1,x1) # torch.Size([12, 128, 32, 32])\n",
    "    y3 = self.decoder3(y2,input) # torch.Size([12, 64, 128, 128])\n",
    "\n",
    "    y4 = self.layer_6(y3)\n",
    "    y5 = self.layer_7(y4) # torch.Size([12, 64, 128, 128])\n",
    "\n",
    "    output = self.last(y5)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = torch.Tensor(12,3,128,128)\n",
    "# models = resnet18_model()\n",
    "# outp = models(inp)\n",
    "# outp.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(key):\n",
    "  model = resnet18_model()\n",
    "  model.load_state_dict(torch.load(\"./weight/\" + key+ \".pth\"))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\your_master\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\your_master\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "resnet18_model(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (layer_0): Conv2d(1, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (layer_1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer_2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder1): Decoder(\n",
       "    (layer1): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder2): Decoder(\n",
       "    (layer1): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder3): Decoder(\n",
       "    (layer1): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(67, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (layer_6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  (layer_7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (last): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salt = resnet18_model()\n",
    "# salt = get_model(\"epoch_best\")\n",
    "\n",
    "# GPU 运算\n",
    "salt.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行一次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "def train(loader_data,model):\n",
    "  running_loss = 0\n",
    "  model.train()\n",
    "  for input,mask in loader_data:\n",
    "    input, mask = input.to(device), mask.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()# 梯度初始化为零\n",
    "    # 使用with，会自动关闭梯度计算\n",
    "    # 设置梯度可算\n",
    "    with torch.set_grad_enabled(True):\n",
    "      logit = model(input)# 进行一次计算\n",
    "      loss = nn.BCEWithLogitsLoss()(logit.squeeze(),mask.squeeze())# 计算误差\n",
    "      loss.backward()# 反馈\n",
    "      optimizer.step()# 进行一次参数更新\n",
    "    running_loss += loss.item()*input.size()[0]# 累计平均误差\n",
    "  epoch_loss = running_loss / len(loader_data)# 计算平均误差\n",
    "  return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行一次测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader_test,model):\n",
    "  running_loss = 0.0\n",
    "  data_size = len(loader_test)\n",
    "  # 测试\n",
    "  model.eval()\n",
    "  for input, mask in loader_test:\n",
    "    input, mask = input.to(device), mask.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "      output = model(input)\n",
    "      loss = nn.BCEWithLogitsLoss()(output.squeeze(), mask.squeeze())\n",
    "    running_loss += loss.item() * input.size(0)\n",
    "  return running_loss/data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主函数部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_loss: 284.2036 val_loss: 275.4077  lr: 0.011982\n",
      "epoch: 2 train_loss: 281.9767 val_loss: 274.7298  lr: 0.011926\n",
      "epoch: 3 train_loss: 281.3796 val_loss: 273.9720  lr: 0.011834\n",
      "epoch: 4 train_loss: 280.1701 val_loss: 275.5302  lr: 0.011707\n",
      "epoch: 5 train_loss: 279.7364 val_loss: 274.5624  lr: 0.011544\n",
      "epoch: 6 train_loss: 278.6682 val_loss: 271.1420  lr: 0.011347\n",
      "epoch: 7 train_loss: 272.8235 val_loss: 279.1965  lr: 0.011117\n",
      "epoch: 8 train_loss: 251.1279 val_loss: 212.0293  lr: 0.010855\n",
      "epoch: 9 train_loss: 233.2190 val_loss: 197.8641  lr: 0.010564\n",
      "epoch: 10 train_loss: 216.8465 val_loss: 209.2730  lr: 0.010244\n",
      "epoch: 11 train_loss: 211.7803 val_loss: 191.4795  lr: 0.009898\n",
      "epoch: 12 train_loss: 200.4510 val_loss: 203.5029  lr: 0.009529\n",
      "epoch: 13 train_loss: 191.0972 val_loss: 185.7816  lr: 0.009137\n",
      "epoch: 14 train_loss: 180.4231 val_loss: 178.6146  lr: 0.008727\n",
      "epoch: 15 train_loss: 165.9935 val_loss: 175.7574  lr: 0.008299\n",
      "epoch: 16 train_loss: 156.4799 val_loss: 196.6050  lr: 0.007858\n",
      "epoch: 17 train_loss: 136.4043 val_loss: 185.2876  lr: 0.007405\n",
      "epoch: 18 train_loss: 119.8617 val_loss: 192.3026  lr: 0.006943\n",
      "epoch: 19 train_loss: 108.1863 val_loss: 214.4593  lr: 0.006475\n",
      "epoch: 20 train_loss: 93.0058 val_loss: 220.6591  lr: 0.006005\n",
      "epoch: 21 train_loss: 88.5914 val_loss: 210.0092  lr: 0.005535\n",
      "epoch: 22 train_loss: 70.9007 val_loss: 197.1464  lr: 0.005067\n",
      "epoch: 23 train_loss: 62.4806 val_loss: 214.2217  lr: 0.004605\n",
      "epoch: 24 train_loss: 53.2874 val_loss: 205.3319  lr: 0.004152\n",
      "epoch: 25 train_loss: 46.7743 val_loss: 223.0399  lr: 0.003711\n",
      "epoch: 26 train_loss: 41.2350 val_loss: 240.5415  lr: 0.003283\n",
      "epoch: 27 train_loss: 36.3209 val_loss: 239.3485  lr: 0.002873\n",
      "epoch: 28 train_loss: 32.5859 val_loss: 245.1957  lr: 0.002481\n",
      "epoch: 29 train_loss: 33.5851 val_loss: 257.7823  lr: 0.002112\n",
      "epoch: 30 train_loss: 28.6462 val_loss: 262.0092  lr: 0.001766\n",
      "epoch: 31 train_loss: 27.2359 val_loss: 263.8551  lr: 0.001446\n",
      "epoch: 32 train_loss: 26.3113 val_loss: 246.9634  lr: 0.001155\n",
      "epoch: 33 train_loss: 24.5153 val_loss: 271.1937  lr: 0.000893\n",
      "epoch: 34 train_loss: 22.4395 val_loss: 279.9093  lr: 0.000663\n",
      "epoch: 35 train_loss: 24.1241 val_loss: 271.6585  lr: 0.000466\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "  if idx == 1:\n",
    "    break\n",
    "\n",
    "  optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "  lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "  # setdiff1d 取不同的元素\n",
    "  train_id = np.setdiff1d(all_ids, fold[idx])\n",
    "  val_id = fold[idx]\n",
    "  # 取出数据\n",
    "  X_train, y_train = get_train_images(train_id)\n",
    "  X_val, y_val = get_train_images(val_id)\n",
    "  # 制作数据集\n",
    "  train_data = TensorDataset(X_train, y_train)\n",
    "  val_data = TensorDataset(X_val, y_val)\n",
    "  # 打乱，制作可迭代数据集\n",
    "  train_loader = DataLoader(train_data,shuffle=True,batch_size=batch_size) \n",
    "  val_loader = DataLoader(val_data,shuffle=False,batch_size=batch_size) \n",
    "\n",
    "  # num_snapshot = 0\n",
    "  lowest_loss = 10000\n",
    "  # last_train_loss = 0.0\n",
    "# 训练\n",
    "  for epoch_ in range(epoch_Num): # 100\n",
    "    train_loss = train(train_loader, salt)\n",
    "    last_train_loss = train_loss\n",
    "    val_loss = test(val_loader, salt)\n",
    "    # 每训练一次调整学习率（退火学习）\n",
    "    if (epoch_ < scheduler_step-1):\n",
    "      lr_scheduler.step()\n",
    "\n",
    "    #\n",
    "    if epoch_ % 10 == 0:\n",
    "      torch.save(salt.state_dict(), \"./weight/\"+ \"epoch_\" + str(epoch_) + '.pth')\n",
    "\n",
    "    if lowest_loss > val_loss:\n",
    "      lowest_loss = val_loss\n",
    "      best_param = salt.state_dict()\n",
    "      torch.save(salt.state_dict(), \"./weight/\"+ \"epoch_best\" + '.pth')\n",
    "\n",
    "    # 调节一个\n",
    "    # if (epoch_ + 1) % scheduler_step == 0:\n",
    "      # torch.save(best_param, \"./weight/\" + str(idx) +\"_\"+ str(num_snapshot) + '.pth')\n",
    "      # 重置优化器，以及退火学习\n",
    "      # optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "      # lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "      # num_snapshot += 1\n",
    "      # lowest_loss = 10000\n",
    "\n",
    "    print('epoch: {} train_loss: {:.4f} val_loss: {:.4f}  lr: {:.6f}'.format(epoch_ + 1, train_loss*100, val_loss*100, lr_scheduler.get_last_lr()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = plt.imread(train_image_dir+\"/\" +all_ids[2] + \".png\")\n",
    "\n",
    "# plt.imshow(img,\"./sdfds.png\") 3.9110 3.7660\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 保存参数\n",
    "\n",
    "|操作|函数|\n",
    "|-|-|\n",
    "|保存|torch.save(model.state_dict(),path)|\n",
    "|读取|model.load_state_dict(torch.load(path))|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 保存模型\n",
    "\n",
    "|操作|函数|\n",
    "|-|-|\n",
    "|保存|torch.save(model,path)|\n",
    "|读取|model = torch.load(path)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6e7463ab38ffa65d2678dd98ae9d6c9783a580bfd91baaccc455120c17d4d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
