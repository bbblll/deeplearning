{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要修改成的数据大小\n",
    "dsize = 128\n",
    "# 最大学习率(优化器)\n",
    "max_lr = 0.012 \n",
    "# 正则项权值的衰减(优化器)\n",
    "weight_decay = 1e-4 \n",
    "# 一般0.9 (优化器)\n",
    "momentum = 0.9 \n",
    "# 最小学习率(退火学习)\n",
    "min_lr = 0.001\n",
    "# 设置GPU运行\n",
    "device = torch.device('cuda')\n",
    "# 退火学习，下降次数\n",
    "scheduler_step = 50\n",
    "# 打包个数\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = './competition_data'\n",
    "save_weight_path = src + '/weight'\n",
    "train_image_dir = src + '/train/images'\n",
    "train_mask_dir = src + '/train/masks'\n",
    "test_image_dir = src + '/test/images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取数据id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = pd.read_csv(src + '/train.csv')\n",
    "fold = (list(range(5))*1000)[:len(depths)] # [0,1,2,3,4,0,1,2...]\n",
    "depths['fold'] = fold # 将数据标记为五份\n",
    "all_ids = depths['id'].values # 取出所有id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片id分为五类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = []\n",
    "for i in range(5):\n",
    "  tem = depths.loc[depths['fold']==i,'id'].values\n",
    "  fold.append(tem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取图片（输入，输出）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_images(ids):\n",
    "  images = []\n",
    "  masks = []\n",
    "  for id in ids:\n",
    "    image = plt.imread(train_image_dir+'/'+id+'.png')[0] / 255\n",
    "    mask = plt.imread(train_mask_dir+'/'+id+'.png')[0] / 255\n",
    "    masks.append(mask)\n",
    "    images.append(image)\n",
    "  return images,masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据集类型\n",
    "数据集类型有三个常用魔法方法\n",
    "1. 初始化（获取参数）\n",
    "2. 获取数据（数据处理，返回数据）\n",
    "3. 获取数据集长度（返回数据集长度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据集\n",
    "class TensorDataset(Dataset):\n",
    "  def __init__(self, data, target):\n",
    "    self.data = data\n",
    "    self.target = target\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # 改变尺寸，并且变为张量\n",
    "    resolved_data = torch.Tensor(\n",
    "      cv2.resize(self.data[index], dsize=(dsize,dsize))\n",
    "    ).reshape(1,dsize,dsize)\n",
    "    # 改变尺寸，并且变为张量\n",
    "    resolved_target = torch.Tensor(\n",
    "      cv2.resize(self.target[index], dsize=(dsize,dsize))\n",
    "    ).reshape(1,dsize,dsize)\n",
    "    # 返回\n",
    "    # (1,128,128),(1,128,128)\n",
    "    return resolved_data,resolved_target\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self,in_size,out_size) -> None:\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.ConvTranspose2d(in_channels=in_size,out_channels=out_size,kernel_size=2,stride=2,padding=0)\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=in_size,out_channels=out_size,stride=1,padding=1,kernel_size=3),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "  def forward(self,x1,x2):\n",
    "    y1 = self.layer1(x1)\n",
    "    tem = torch.cat((y1,x2),dim=1)\n",
    "    y2 = self.layer2(tem)\n",
    "    return y2\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=1,out_channels=4,stride=2,padding=1,kernel_size=3),\n",
    "      nn.BatchNorm2d(num_features=4),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=4,out_channels=8,stride=2,padding=1,kernel_size=3),\n",
    "      nn.BatchNorm2d(num_features=8),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.layer3 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=8,out_channels=16,stride=2,padding=1,kernel_size=3),\n",
    "      nn.BatchNorm2d(num_features=16),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.layer4 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=16,out_channels=32,stride=2,padding=1,kernel_size=3),\n",
    "      nn.BatchNorm2d(num_features=32),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.decoder1 = Decoder(32,16)\n",
    "    self.decoder2 = Decoder(16,8)\n",
    "    self.decoder3 = Decoder(8,4)\n",
    "    self.last = nn.Sequential(\n",
    "      nn.ConvTranspose2d(in_channels=4,out_channels=1,kernel_size=2,stride=2),\n",
    "      nn.Conv2d(in_channels=1,kernel_size=5,out_channels=1,padding=4),\n",
    "      nn.Conv2d(in_channels=1,kernel_size=5,out_channels=1)\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "  def forward(self,input):\n",
    "    x1 = self.layer1(input) # torch.Size([18, 4, 64, 64])\n",
    "    x2 = self.layer2(x1) # torch.Size([18, 8, 32, 32])\n",
    "    x3 = self.layer3(x2) # torch.Size([18, 16, 16, 16])\n",
    "    x4 = self.layer4(x3) # torch.Size([18, 32, 8, 8])\n",
    "\n",
    "    y1 = self.decoder1(x4,x3) # torch.Size([18, 16, 16, 16])\n",
    "    y2 = self.decoder2(y1,x2)# torch.Size([18, 8, 32, 32])\n",
    "    y3 = self.decoder3(y2,x1) # torch.Size([18, 4, 64, 64])\n",
    "    output = self.last(y3) # torch.Size([18, 1, 128, 128])\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleUNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (decoder1): Decoder(\n",
       "    (layer1): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder2): Decoder(\n",
       "    (layer1): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder3): Decoder(\n",
       "    (layer1): ConvTranspose2d(8, 4, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (last): Sequential(\n",
       "    (0): ConvTranspose2d(4, 1, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4))\n",
       "    (2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salt = SimpleUNet()\n",
    "\n",
    "# GPU 运算\n",
    "salt.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行一次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "def train(loader_data,model):\n",
    "  running_loss = 0\n",
    "  model.train()\n",
    "  for input,mask in loader_data:\n",
    "    input, mask = input.to(device), mask.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()# 梯度初始化为零\n",
    "    # 使用with，会自动关闭梯度计算\n",
    "    # 设置梯度可算\n",
    "    with torch.set_grad_enabled(True):\n",
    "      logit = model(input)# 进行一次计算\n",
    "      loss = nn.BCEWithLogitsLoss()(logit.squeeze(),mask.squeeze())# 计算误差\n",
    "      loss.backward()# 反馈\n",
    "      optimizer.step()# 进行一次参数更新\n",
    "    running_loss += loss.item()*input.size()[0]# 累计平均误差\n",
    "  epoch_loss = running_loss / len(loader_data)# 计算平均误差\n",
    "  return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行一次测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader_test,model):\n",
    "  running_loss = 0.0\n",
    "  data_size = len(loader_test)\n",
    "  # 测试\n",
    "  model.eval()\n",
    "  for input, mask in loader_test:\n",
    "    input, mask = input.to(device), mask.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "      output = model(input)\n",
    "      loss = nn.BCEWithLogitsLoss()(output.squeeze(), mask.squeeze())\n",
    "    running_loss += loss.item() * input.size(0)\n",
    "  return running_loss/data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主函数部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_loss: 8.341 val_loss: 3.621\n",
      "epoch: 2 train_loss: 3.733 val_loss: 3.604\n",
      "epoch: 3 train_loss: 3.718 val_loss: 3.592\n",
      "epoch: 4 train_loss: 3.705 val_loss: 3.582\n",
      "epoch: 5 train_loss: 3.695 val_loss: 3.570\n",
      "epoch: 6 train_loss: 3.687 val_loss: 3.564\n",
      "epoch: 7 train_loss: 3.681 val_loss: 3.566\n",
      "epoch: 8 train_loss: 3.677 val_loss: 3.553\n",
      "epoch: 9 train_loss: 3.671 val_loss: 3.547\n",
      "epoch: 10 train_loss: 3.666 val_loss: 3.559\n",
      "epoch: 11 train_loss: 3.661 val_loss: 3.540\n",
      "epoch: 12 train_loss: 3.658 val_loss: 3.535\n",
      "epoch: 13 train_loss: 3.654 val_loss: 3.532\n",
      "epoch: 14 train_loss: 3.652 val_loss: 3.532\n",
      "epoch: 15 train_loss: 3.648 val_loss: 3.526\n",
      "epoch: 16 train_loss: 3.645 val_loss: 3.526\n",
      "epoch: 17 train_loss: 3.643 val_loss: 3.521\n",
      "epoch: 18 train_loss: 3.640 val_loss: 3.519\n",
      "epoch: 19 train_loss: 3.638 val_loss: 3.517\n",
      "epoch: 20 train_loss: 3.636 val_loss: 3.515\n",
      "epoch: 21 train_loss: 3.634 val_loss: 3.513\n",
      "epoch: 22 train_loss: 3.632 val_loss: 3.513\n",
      "epoch: 23 train_loss: 3.631 val_loss: 3.510\n",
      "epoch: 24 train_loss: 3.629 val_loss: 3.512\n",
      "epoch: 25 train_loss: 3.628 val_loss: 3.508\n",
      "epoch: 26 train_loss: 3.627 val_loss: 3.507\n",
      "epoch: 27 train_loss: 3.626 val_loss: 3.505\n",
      "epoch: 28 train_loss: 3.624 val_loss: 3.504\n",
      "epoch: 29 train_loss: 3.623 val_loss: 3.503\n",
      "epoch: 30 train_loss: 3.623 val_loss: 3.502\n",
      "epoch: 31 train_loss: 3.621 val_loss: 3.503\n",
      "epoch: 32 train_loss: 3.621 val_loss: 3.501\n",
      "epoch: 33 train_loss: 3.619 val_loss: 3.504\n",
      "epoch: 34 train_loss: 3.620 val_loss: 3.500\n",
      "epoch: 35 train_loss: 3.619 val_loss: 3.500\n",
      "epoch: 36 train_loss: 3.618 val_loss: 3.499\n",
      "epoch: 37 train_loss: 3.618 val_loss: 3.500\n",
      "epoch: 38 train_loss: 3.618 val_loss: 3.499\n",
      "epoch: 39 train_loss: 3.617 val_loss: 3.499\n",
      "epoch: 40 train_loss: 3.617 val_loss: 3.499\n",
      "epoch: 41 train_loss: 3.617 val_loss: 3.498\n",
      "epoch: 42 train_loss: 3.616 val_loss: 3.497\n",
      "epoch: 43 train_loss: 3.616 val_loss: 3.497\n",
      "epoch: 44 train_loss: 3.616 val_loss: 3.498\n",
      "epoch: 45 train_loss: 3.615 val_loss: 3.497\n",
      "epoch: 46 train_loss: 3.615 val_loss: 3.497\n",
      "epoch: 47 train_loss: 3.615 val_loss: 3.496\n",
      "epoch: 48 train_loss: 3.615 val_loss: 3.497\n",
      "epoch: 49 train_loss: 3.615 val_loss: 3.497\n",
      "epoch: 50 train_loss: 3.615 val_loss: 3.496\n",
      "epoch: 51 train_loss: 3.615 val_loss: 3.495\n",
      "epoch: 52 train_loss: 3.614 val_loss: 3.493\n",
      "epoch: 53 train_loss: 3.613 val_loss: 3.492\n",
      "epoch: 54 train_loss: 3.611 val_loss: 3.491\n",
      "epoch: 55 train_loss: 3.610 val_loss: 3.489\n",
      "epoch: 56 train_loss: 3.609 val_loss: 3.488\n",
      "epoch: 57 train_loss: 3.608 val_loss: 3.487\n",
      "epoch: 58 train_loss: 3.606 val_loss: 3.487\n",
      "epoch: 59 train_loss: 3.606 val_loss: 3.490\n",
      "epoch: 60 train_loss: 3.605 val_loss: 3.486\n",
      "epoch: 61 train_loss: 3.604 val_loss: 3.484\n",
      "epoch: 62 train_loss: 3.603 val_loss: 3.487\n",
      "epoch: 63 train_loss: 3.603 val_loss: 3.484\n",
      "epoch: 64 train_loss: 3.602 val_loss: 3.482\n",
      "epoch: 65 train_loss: 3.601 val_loss: 3.483\n",
      "epoch: 66 train_loss: 3.601 val_loss: 3.481\n",
      "epoch: 67 train_loss: 3.600 val_loss: 3.484\n",
      "epoch: 68 train_loss: 3.599 val_loss: 3.487\n",
      "epoch: 69 train_loss: 3.598 val_loss: 3.482\n",
      "epoch: 70 train_loss: 3.599 val_loss: 3.479\n",
      "epoch: 71 train_loss: 3.598 val_loss: 3.479\n",
      "epoch: 72 train_loss: 3.598 val_loss: 3.478\n",
      "epoch: 73 train_loss: 3.597 val_loss: 3.478\n",
      "epoch: 74 train_loss: 3.597 val_loss: 3.478\n",
      "epoch: 75 train_loss: 3.596 val_loss: 3.478\n",
      "epoch: 76 train_loss: 3.596 val_loss: 3.482\n",
      "epoch: 77 train_loss: 3.596 val_loss: 3.478\n",
      "epoch: 78 train_loss: 3.596 val_loss: 3.478\n",
      "epoch: 79 train_loss: 3.595 val_loss: 3.477\n",
      "epoch: 80 train_loss: 3.595 val_loss: 3.476\n",
      "epoch: 81 train_loss: 3.595 val_loss: 3.476\n",
      "epoch: 82 train_loss: 3.595 val_loss: 3.477\n",
      "epoch: 83 train_loss: 3.594 val_loss: 3.477\n",
      "epoch: 84 train_loss: 3.594 val_loss: 3.476\n",
      "epoch: 85 train_loss: 3.594 val_loss: 3.477\n",
      "epoch: 86 train_loss: 3.594 val_loss: 3.476\n",
      "epoch: 87 train_loss: 3.594 val_loss: 3.475\n",
      "epoch: 88 train_loss: 3.594 val_loss: 3.476\n",
      "epoch: 89 train_loss: 3.594 val_loss: 3.476\n",
      "epoch: 90 train_loss: 3.594 val_loss: 3.476\n",
      "epoch: 91 train_loss: 3.594 val_loss: 3.475\n",
      "epoch: 92 train_loss: 3.594 val_loss: 3.475\n",
      "epoch: 93 train_loss: 3.593 val_loss: 3.476\n",
      "epoch: 94 train_loss: 3.593 val_loss: 3.475\n",
      "epoch: 95 train_loss: 3.593 val_loss: 3.476\n",
      "epoch: 96 train_loss: 3.593 val_loss: 3.475\n",
      "epoch: 97 train_loss: 3.593 val_loss: 3.475\n",
      "epoch: 98 train_loss: 3.593 val_loss: 3.475\n",
      "epoch: 99 train_loss: 3.593 val_loss: 3.475\n",
      "epoch: 100 train_loss: 3.593 val_loss: 3.475\n",
      "epoch: 101 train_loss: 3.594 val_loss: 3.474\n",
      "epoch: 102 train_loss: 3.594 val_loss: 3.477\n",
      "epoch: 103 train_loss: 3.593 val_loss: 3.474\n",
      "epoch: 104 train_loss: 3.593 val_loss: 3.473\n",
      "epoch: 105 train_loss: 3.593 val_loss: 3.474\n",
      "epoch: 106 train_loss: 3.592 val_loss: 3.473\n",
      "epoch: 107 train_loss: 3.592 val_loss: 3.473\n",
      "epoch: 108 train_loss: 3.592 val_loss: 3.473\n",
      "epoch: 109 train_loss: 3.591 val_loss: 3.474\n",
      "epoch: 110 train_loss: 3.591 val_loss: 3.476\n",
      "epoch: 111 train_loss: 3.591 val_loss: 3.473\n",
      "epoch: 112 train_loss: 3.591 val_loss: 3.474\n",
      "epoch: 113 train_loss: 3.591 val_loss: 3.476\n",
      "epoch: 114 train_loss: 3.591 val_loss: 3.471\n",
      "epoch: 115 train_loss: 3.590 val_loss: 3.471\n",
      "epoch: 116 train_loss: 3.589 val_loss: 3.472\n",
      "epoch: 117 train_loss: 3.590 val_loss: 3.473\n",
      "epoch: 118 train_loss: 3.589 val_loss: 3.471\n",
      "epoch: 119 train_loss: 3.589 val_loss: 3.470\n",
      "epoch: 120 train_loss: 3.589 val_loss: 3.471\n",
      "epoch: 121 train_loss: 3.589 val_loss: 3.470\n",
      "epoch: 122 train_loss: 3.589 val_loss: 3.470\n",
      "epoch: 123 train_loss: 3.589 val_loss: 3.470\n",
      "epoch: 124 train_loss: 3.589 val_loss: 3.470\n",
      "epoch: 125 train_loss: 3.589 val_loss: 3.471\n",
      "epoch: 126 train_loss: 3.589 val_loss: 3.470\n",
      "epoch: 127 train_loss: 3.588 val_loss: 3.473\n",
      "epoch: 128 train_loss: 3.588 val_loss: 3.470\n",
      "epoch: 129 train_loss: 3.588 val_loss: 3.471\n",
      "epoch: 130 train_loss: 3.588 val_loss: 3.470\n",
      "epoch: 131 train_loss: 3.588 val_loss: 3.470\n",
      "epoch: 132 train_loss: 3.588 val_loss: 3.471\n",
      "epoch: 133 train_loss: 3.588 val_loss: 3.470\n",
      "epoch: 134 train_loss: 3.588 val_loss: 3.470\n",
      "epoch: 135 train_loss: 3.588 val_loss: 3.470\n",
      "epoch: 136 train_loss: 3.588 val_loss: 3.470\n",
      "epoch: 137 train_loss: 3.587 val_loss: 3.469\n",
      "epoch: 138 train_loss: 3.588 val_loss: 3.470\n",
      "epoch: 139 train_loss: 3.588 val_loss: 3.470\n",
      "epoch: 140 train_loss: 3.587 val_loss: 3.470\n",
      "epoch: 141 train_loss: 3.587 val_loss: 3.470\n",
      "epoch: 142 train_loss: 3.588 val_loss: 3.470\n",
      "epoch: 143 train_loss: 3.587 val_loss: 3.470\n",
      "epoch: 144 train_loss: 3.587 val_loss: 3.470\n",
      "epoch: 145 train_loss: 3.587 val_loss: 3.470\n",
      "epoch: 146 train_loss: 3.587 val_loss: 3.470\n",
      "epoch: 147 train_loss: 3.587 val_loss: 3.470\n",
      "epoch: 148 train_loss: 3.587 val_loss: 3.470\n",
      "epoch: 149 train_loss: 3.587 val_loss: 3.470\n",
      "epoch: 150 train_loss: 3.587 val_loss: 3.470\n",
      "epoch: 151 train_loss: 3.588 val_loss: 3.469\n",
      "epoch: 152 train_loss: 3.589 val_loss: 3.470\n",
      "epoch: 153 train_loss: 3.588 val_loss: 3.469\n",
      "epoch: 154 train_loss: 3.587 val_loss: 3.471\n",
      "epoch: 155 train_loss: 3.587 val_loss: 3.470\n",
      "epoch: 156 train_loss: 3.588 val_loss: 3.468\n",
      "epoch: 157 train_loss: 3.588 val_loss: 3.468\n",
      "epoch: 158 train_loss: 3.588 val_loss: 3.468\n",
      "epoch: 159 train_loss: 3.587 val_loss: 3.468\n",
      "epoch: 160 train_loss: 3.587 val_loss: 3.472\n",
      "epoch: 161 train_loss: 3.587 val_loss: 3.468\n",
      "epoch: 162 train_loss: 3.587 val_loss: 3.474\n",
      "epoch: 163 train_loss: 3.588 val_loss: 3.470\n",
      "epoch: 164 train_loss: 3.586 val_loss: 3.468\n",
      "epoch: 165 train_loss: 3.586 val_loss: 3.469\n",
      "epoch: 166 train_loss: 3.587 val_loss: 3.468\n",
      "epoch: 167 train_loss: 3.586 val_loss: 3.468\n",
      "epoch: 168 train_loss: 3.586 val_loss: 3.469\n",
      "epoch: 169 train_loss: 3.587 val_loss: 3.469\n",
      "epoch: 170 train_loss: 3.586 val_loss: 3.468\n",
      "epoch: 171 train_loss: 3.586 val_loss: 3.468\n",
      "epoch: 172 train_loss: 3.586 val_loss: 3.471\n",
      "epoch: 173 train_loss: 3.586 val_loss: 3.467\n",
      "epoch: 174 train_loss: 3.586 val_loss: 3.467\n",
      "epoch: 175 train_loss: 3.586 val_loss: 3.469\n",
      "epoch: 176 train_loss: 3.586 val_loss: 3.469\n",
      "epoch: 177 train_loss: 3.585 val_loss: 3.472\n",
      "epoch: 178 train_loss: 3.586 val_loss: 3.467\n",
      "epoch: 179 train_loss: 3.586 val_loss: 3.468\n",
      "epoch: 180 train_loss: 3.586 val_loss: 3.469\n",
      "epoch: 181 train_loss: 3.586 val_loss: 3.468\n",
      "epoch: 182 train_loss: 3.586 val_loss: 3.468\n",
      "epoch: 183 train_loss: 3.586 val_loss: 3.467\n",
      "epoch: 184 train_loss: 3.585 val_loss: 3.467\n",
      "epoch: 185 train_loss: 3.586 val_loss: 3.467\n",
      "epoch: 186 train_loss: 3.585 val_loss: 3.468\n",
      "epoch: 187 train_loss: 3.585 val_loss: 3.468\n",
      "epoch: 188 train_loss: 3.586 val_loss: 3.467\n",
      "epoch: 189 train_loss: 3.585 val_loss: 3.468\n",
      "epoch: 190 train_loss: 3.585 val_loss: 3.468\n",
      "epoch: 191 train_loss: 3.585 val_loss: 3.468\n",
      "epoch: 192 train_loss: 3.585 val_loss: 3.467\n",
      "epoch: 193 train_loss: 3.585 val_loss: 3.468\n",
      "epoch: 194 train_loss: 3.585 val_loss: 3.467\n",
      "epoch: 195 train_loss: 3.585 val_loss: 3.467\n",
      "epoch: 196 train_loss: 3.585 val_loss: 3.467\n",
      "epoch: 197 train_loss: 3.585 val_loss: 3.468\n",
      "epoch: 198 train_loss: 3.585 val_loss: 3.468\n",
      "epoch: 199 train_loss: 3.585 val_loss: 3.468\n",
      "epoch: 200 train_loss: 3.585 val_loss: 3.468\n",
      "epoch: 201 train_loss: 3.586 val_loss: 3.468\n",
      "epoch: 202 train_loss: 3.586 val_loss: 3.471\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\YOUR_M~1\\AppData\\Local\\Temp/ipykernel_4768/2058465814.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# 训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mepoch_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 300\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msalt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msalt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# 每训练一次调整学习率（退火学习）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\YOUR_M~1\\AppData\\Local\\Temp/ipykernel_4768/2065580904.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(loader_data, model)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# 设置梯度可算\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m       \u001b[0mlogit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# 进行一次计算\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# 计算误差\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m       \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# 反馈\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\your_master\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\YOUR_M~1\\AppData\\Local\\Temp/ipykernel_4768/2162877077.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     49\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# torch.Size([18, 4, 64, 64])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# torch.Size([18, 8, 32, 32])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mx3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# torch.Size([18, 16, 16, 16])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mx4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# torch.Size([18, 32, 8, 8])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\your_master\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\your_master\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\your_master\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\your_master\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\your_master\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    451\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 453\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    454\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "\n",
    "  optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "  lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "  # setdiff1d 取不同的元素\n",
    "  train_id = np.setdiff1d(all_ids, fold[idx])\n",
    "  val_id = fold[idx]\n",
    "  # 取出数据\n",
    "  X_train, y_train = get_train_images(train_id)\n",
    "  X_val, y_val = get_train_images(val_id)\n",
    "  # 制作数据集\n",
    "  train_data = TensorDataset(X_train, y_train)\n",
    "  val_data = TensorDataset(X_val, y_val)\n",
    "  # 打乱，制作可迭代数据集\n",
    "  train_loader = DataLoader(train_data,shuffle=True,batch_size=batch_size) \n",
    "  val_loader = DataLoader(val_data,shuffle=False,batch_size=batch_size) \n",
    "\n",
    "  num_snapshot = 0\n",
    "  lowest_loss = 10000\n",
    "# 训练\n",
    "  for epoch_ in range(300): # 300\n",
    "    train_loss = train(train_loader, salt)\n",
    "    val_loss = test(val_loader, salt)\n",
    "    # 每训练一次调整学习率（退火学习）\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    if lowest_loss > val_loss:\n",
    "      lowest_loss = val_loss\n",
    "      best_param = salt.state_dict()\n",
    "\n",
    "    # 调节一个\n",
    "    if (epoch_ + 1) % scheduler_step == 0:\n",
    "      torch.save(best_param, \"./weight/\" + str(idx) +\"_\"+ str(num_snapshot) + '.pth')\n",
    "      # 重置优化器，以及退火学习\n",
    "      optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "      lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "      num_snapshot += 1\n",
    "      lowest_loss = 10000\n",
    "\n",
    "    print('epoch: {} train_loss: {:.3f} val_loss: {:.3f}'.format(epoch_ + 1, train_loss*100, val_loss*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 保存参数\n",
    "\n",
    "|操作|函数|\n",
    "|-|-|\n",
    "|保存|torch.save(model.state_dict(),path)|\n",
    "|读取|torch.load(path)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model():\n",
    "  model = SimpleUNet()\n",
    "  model.load_state_dict(torch.load(\"./weight/4_4.pth\"))\n",
    "  return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6e7463ab38ffa65d2678dd98ae9d6c9783a580bfd91baaccc455120c17d4d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
