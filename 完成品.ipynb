{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要修改成的数据大小\n",
    "dsize = 128\n",
    "# 最大学习率(优化器)\n",
    "max_lr = 0.012 \n",
    "# 正则项权值的衰减(优化器)\n",
    "weight_decay = 1e-4 \n",
    "# 一般0.9 (优化器)\n",
    "momentum = 0.9 \n",
    "# 最小学习率(退火学习)\n",
    "min_lr = 0.001\n",
    "# 设置GPU运行\n",
    "device = torch.device('cuda')\n",
    "# 退火学习，下降次数\n",
    "scheduler_step = 300\n",
    "# 打包个数\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = './competition_data'\n",
    "save_weight_path = src + '/weight'\n",
    "train_image_dir = src + '/train/images'\n",
    "train_mask_dir = src + '/train/masks'\n",
    "test_image_dir = src + '/test/images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取数据id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = pd.read_csv(src + '/train.csv')\n",
    "fold = (list(range(5))*1000)[:len(depths)] # [0,1,2,3,4,0,1,2...]\n",
    "depths['fold'] = fold # 将数据标记为五份\n",
    "all_ids = depths['id'].values # 取出所有id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片id分为五类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = []\n",
    "for i in range(5):\n",
    "  tem = depths.loc[depths['fold']==i,'id'].values\n",
    "  fold.append(tem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取图片（输入，输出）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_images(ids):\n",
    "  images = []\n",
    "  masks = []\n",
    "  for id in ids:\n",
    "    image = plt.imread(train_image_dir+'/'+id+'.png')[0] / 255\n",
    "    mask = plt.imread(train_mask_dir+'/'+id+'.png')[0] / 255\n",
    "    masks.append(mask)\n",
    "    images.append(image)\n",
    "  return images,masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建数据集类型\n",
    "数据集类型有三个常用魔法方法\n",
    "1. 初始化（获取参数）\n",
    "2. 获取数据（数据处理，返回数据）\n",
    "3. 获取数据集长度（返回数据集长度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据集\n",
    "class TensorDataset(Dataset):\n",
    "  def __init__(self, data, target):\n",
    "    self.data = data\n",
    "    self.target = target\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # 改变尺寸，并且变为张量\n",
    "    resolved_data = torch.Tensor(\n",
    "      cv2.resize(self.data[index], dsize=(dsize,dsize))\n",
    "    ).reshape(1,dsize,dsize)\n",
    "    # 改变尺寸，并且变为张量\n",
    "    resolved_target = torch.Tensor(\n",
    "      cv2.resize(self.target[index], dsize=(dsize,dsize))\n",
    "    ).reshape(1,dsize,dsize)\n",
    "    # 返回\n",
    "    # (1,128,128),(1,128,128)\n",
    "    return resolved_data,resolved_target\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self,in_size,out_size,mid_size) -> None:\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.ConvTranspose2d(in_channels=in_size,out_channels=out_size,kernel_size=2,stride=2,padding=0)\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=mid_size,out_channels=out_size,stride=1,padding=1,kernel_size=3),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "  def forward(self,x1,x2):\n",
    "    y1 = self.layer1(x1)\n",
    "    tem = torch.cat((y1,x2),dim=1)\n",
    "    y2 = self.layer2(tem)\n",
    "    return y2\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=1,out_channels=8,stride=2,padding=1,kernel_size=3),\n",
    "      nn.BatchNorm2d(num_features=8),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=8,out_channels=64,stride=2,padding=1,kernel_size=3),\n",
    "      nn.BatchNorm2d(num_features=64),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.layer3 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=64,out_channels=512,stride=2,padding=1,kernel_size=3),\n",
    "      nn.BatchNorm2d(num_features=512),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.layer4 = nn.Sequential(\n",
    "      nn.Conv2d(in_channels=512,out_channels=1024,stride=2,padding=1,kernel_size=3),\n",
    "      nn.BatchNorm2d(num_features=1024),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    self.decoder1 = Decoder(1024,512,512+512)\n",
    "    self.decoder2 = Decoder(512,256,256+64)\n",
    "    self.decoder3 = Decoder(256,128,128+8)\n",
    "    self.last = nn.Sequential(\n",
    "      nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "      nn.Conv2d(in_channels=128,kernel_size=5,out_channels=64,padding=2),\n",
    "      nn.Conv2d(in_channels=64,kernel_size=1,out_channels=1)\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "  def forward(self,input):\n",
    "    x1 = self.layer1(input) # torch.Size([18, 8, 64, 64])\n",
    "    x2 = self.layer2(x1) # torch.Size([18, 64, 32, 32])\n",
    "    x3 = self.layer3(x2) # torch.Size([18, 512, 16, 16])\n",
    "    x4 = self.layer4(x3) # torch.Size([18, 1024, 8, 8])\n",
    "\n",
    "    y1 = self.decoder1(x4,x3) # torch.Size([18, 512, 16, 16])\n",
    "    y2 = self.decoder2(y1,x2)# torch.Size([18, 256, 32, 32])\n",
    "    y3 = self.decoder3(y2,x1) # torch.Size([18, 128, 64, 64])\n",
    "    output = self.last(y3) # torch.Size([18, 1, 128, 128])\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = torch.Tensor(12,1,128,128)\n",
    "# models = SimpleUNet()\n",
    "# outp = models(inp)\n",
    "# outp.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(key):\n",
    "  model = SimpleUNet()\n",
    "  model.load_state_dict(torch.load(\"./weight/\" + key+ \".pth\"))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleUNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(8, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(64, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (decoder1): Decoder(\n",
       "    (layer1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder2): Decoder(\n",
       "    (layer1): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder3): Decoder(\n",
       "    (layer1): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (layer2): Sequential(\n",
       "      (0): Conv2d(136, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (last): Sequential(\n",
       "    (0): UpsamplingBilinear2d(scale_factor=2.0, mode=bilinear)\n",
       "    (1): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salt = SimpleUNet()\n",
    "# salt = get_model(\"0_4\")\n",
    "\n",
    "# GPU 运算\n",
    "salt.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行一次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "def train(loader_data,model):\n",
    "  running_loss = 0\n",
    "  model.train()\n",
    "  for input,mask in loader_data:\n",
    "    input, mask = input.to(device), mask.to(device)\n",
    "    \n",
    "    optimizer.zero_grad()# 梯度初始化为零\n",
    "    # 使用with，会自动关闭梯度计算\n",
    "    # 设置梯度可算\n",
    "    with torch.set_grad_enabled(True):\n",
    "      logit = model(input)# 进行一次计算\n",
    "      loss = nn.BCEWithLogitsLoss()(logit.squeeze(),mask.squeeze())# 计算误差\n",
    "      loss.backward()# 反馈\n",
    "      optimizer.step()# 进行一次参数更新\n",
    "    running_loss += loss.item()*input.size()[0]# 累计平均误差\n",
    "  epoch_loss = running_loss / len(loader_data)# 计算平均误差\n",
    "  return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行一次测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader_test,model):\n",
    "  running_loss = 0.0\n",
    "  data_size = len(loader_test)\n",
    "  # 测试\n",
    "  model.eval()\n",
    "  for input, mask in loader_test:\n",
    "    input, mask = input.to(device), mask.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "      output = model(input)\n",
    "      loss = nn.BCEWithLogitsLoss()(output.squeeze(), mask.squeeze())\n",
    "    running_loss += loss.item() * input.size(0)\n",
    "  return running_loss/data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主函数部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_loss: 10.5422 val_loss: 3.6240  lr: 0.0120\n",
      "epoch: 2 train_loss: 3.7150 val_loss: 3.5789  lr: 0.0120\n",
      "epoch: 3 train_loss: 3.6798 val_loss: 3.5524  lr: 0.0120\n",
      "epoch: 4 train_loss: 3.6596 val_loss: 3.5315  lr: 0.0120\n",
      "epoch: 5 train_loss: 3.6456 val_loss: 3.5178  lr: 0.0120\n",
      "epoch: 6 train_loss: 3.6320 val_loss: 3.5071  lr: 0.0120\n",
      "epoch: 7 train_loss: 3.6260 val_loss: 3.4994  lr: 0.0120\n",
      "epoch: 8 train_loss: 3.6175 val_loss: 3.4909  lr: 0.0120\n",
      "epoch: 9 train_loss: 3.6123 val_loss: 3.4872  lr: 0.0120\n",
      "epoch: 10 train_loss: 3.6081 val_loss: 3.4810  lr: 0.0120\n",
      "epoch: 11 train_loss: 3.6038 val_loss: 3.4777  lr: 0.0120\n",
      "epoch: 12 train_loss: 3.5978 val_loss: 3.4804  lr: 0.0120\n",
      "epoch: 13 train_loss: 3.5955 val_loss: 3.4748  lr: 0.0119\n",
      "epoch: 14 train_loss: 3.5941 val_loss: 3.4679  lr: 0.0119\n",
      "epoch: 15 train_loss: 3.5923 val_loss: 3.4664  lr: 0.0119\n",
      "epoch: 16 train_loss: 3.5892 val_loss: 3.4657  lr: 0.0119\n",
      "epoch: 17 train_loss: 3.5862 val_loss: 3.4635  lr: 0.0119\n",
      "epoch: 18 train_loss: 3.5847 val_loss: 3.4610  lr: 0.0119\n",
      "epoch: 19 train_loss: 3.5840 val_loss: 3.4596  lr: 0.0119\n",
      "epoch: 20 train_loss: 3.5828 val_loss: 3.4585  lr: 0.0119\n",
      "epoch: 21 train_loss: 3.5794 val_loss: 3.4564  lr: 0.0119\n",
      "epoch: 22 train_loss: 3.5801 val_loss: 3.4584  lr: 0.0119\n",
      "epoch: 23 train_loss: 3.5792 val_loss: 3.4579  lr: 0.0118\n",
      "epoch: 24 train_loss: 3.5769 val_loss: 3.4524  lr: 0.0118\n",
      "epoch: 25 train_loss: 3.5741 val_loss: 3.4519  lr: 0.0118\n",
      "epoch: 26 train_loss: 3.5766 val_loss: 3.4527  lr: 0.0118\n",
      "epoch: 27 train_loss: 3.5737 val_loss: 3.4502  lr: 0.0118\n",
      "epoch: 28 train_loss: 3.5722 val_loss: 3.4483  lr: 0.0118\n",
      "epoch: 29 train_loss: 3.5719 val_loss: 3.4476  lr: 0.0117\n",
      "epoch: 30 train_loss: 3.5710 val_loss: 3.4467  lr: 0.0117\n",
      "epoch: 31 train_loss: 3.5717 val_loss: 3.4499  lr: 0.0117\n",
      "epoch: 32 train_loss: 3.5695 val_loss: 3.4457  lr: 0.0117\n",
      "epoch: 33 train_loss: 3.5679 val_loss: 3.4457  lr: 0.0117\n",
      "epoch: 34 train_loss: 3.5669 val_loss: 3.4478  lr: 0.0117\n",
      "epoch: 35 train_loss: 3.5677 val_loss: 3.4442  lr: 0.0116\n",
      "epoch: 36 train_loss: 3.5645 val_loss: 3.4430  lr: 0.0116\n",
      "epoch: 37 train_loss: 3.5659 val_loss: 3.4428  lr: 0.0116\n",
      "epoch: 38 train_loss: 3.5650 val_loss: 3.4416  lr: 0.0116\n",
      "epoch: 39 train_loss: 3.5662 val_loss: 3.4428  lr: 0.0115\n",
      "epoch: 40 train_loss: 3.5650 val_loss: 3.4418  lr: 0.0115\n",
      "epoch: 41 train_loss: 3.5639 val_loss: 3.4411  lr: 0.0115\n",
      "epoch: 42 train_loss: 3.5626 val_loss: 3.4408  lr: 0.0115\n",
      "epoch: 43 train_loss: 3.5625 val_loss: 3.4387  lr: 0.0115\n",
      "epoch: 44 train_loss: 3.5629 val_loss: 3.4423  lr: 0.0114\n",
      "epoch: 45 train_loss: 3.5625 val_loss: 3.4426  lr: 0.0114\n",
      "epoch: 46 train_loss: 3.5611 val_loss: 3.4408  lr: 0.0114\n",
      "epoch: 47 train_loss: 3.5592 val_loss: 3.4392  lr: 0.0113\n",
      "epoch: 48 train_loss: 3.5605 val_loss: 3.4360  lr: 0.0113\n",
      "epoch: 49 train_loss: 3.5605 val_loss: 3.4379  lr: 0.0113\n",
      "epoch: 50 train_loss: 3.5604 val_loss: 3.4363  lr: 0.0113\n",
      "epoch: 51 train_loss: 3.5587 val_loss: 3.4340  lr: 0.0112\n",
      "epoch: 52 train_loss: 3.5588 val_loss: 3.4363  lr: 0.0112\n",
      "epoch: 53 train_loss: 3.5584 val_loss: 3.4455  lr: 0.0112\n",
      "epoch: 54 train_loss: 3.5593 val_loss: 3.4356  lr: 0.0111\n",
      "epoch: 55 train_loss: 3.5578 val_loss: 3.4366  lr: 0.0111\n",
      "epoch: 56 train_loss: 3.5581 val_loss: 3.4340  lr: 0.0111\n",
      "epoch: 57 train_loss: 3.5593 val_loss: 3.4335  lr: 0.0110\n",
      "epoch: 58 train_loss: 3.5564 val_loss: 3.4320  lr: 0.0110\n",
      "epoch: 59 train_loss: 3.5575 val_loss: 3.4339  lr: 0.0110\n",
      "epoch: 60 train_loss: 3.5563 val_loss: 3.4331  lr: 0.0109\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "  if idx == 1:\n",
    "    break\n",
    "\n",
    "  optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "  lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "  # setdiff1d 取不同的元素\n",
    "  train_id = np.setdiff1d(all_ids, fold[idx])\n",
    "  val_id = fold[idx]\n",
    "  # 取出数据\n",
    "  X_train, y_train = get_train_images(train_id)\n",
    "  X_val, y_val = get_train_images(val_id)\n",
    "  # 制作数据集\n",
    "  train_data = TensorDataset(X_train, y_train)\n",
    "  val_data = TensorDataset(X_val, y_val)\n",
    "  # 打乱，制作可迭代数据集\n",
    "  train_loader = DataLoader(train_data,shuffle=True,batch_size=batch_size) \n",
    "  val_loader = DataLoader(val_data,shuffle=False,batch_size=batch_size) \n",
    "\n",
    "  num_snapshot = 0\n",
    "  lowest_loss = 10000\n",
    "# 训练\n",
    "  for epoch_ in range(300): # 300\n",
    "    train_loss = train(train_loader, salt)\n",
    "    val_loss = test(val_loader, salt)\n",
    "    # 每训练一次调整学习率（退火学习）\n",
    "    lr_scheduler.step()\n",
    "    if epoch_ % 5 == 0:\n",
    "      torch.save(salt.state_dict(), \"./weight/\"+ \"epoch_\" + str(epoch_) + '.pth')\n",
    "\n",
    "    # if lowest_loss > val_loss:\n",
    "    #   lowest_loss = val_loss\n",
    "    #   best_param = salt.state_dict()\n",
    "\n",
    "    # 调节一个\n",
    "    if (epoch_ + 1) % scheduler_step == 0:\n",
    "      # torch.save(best_param, \"./weight/\" + str(idx) +\"_\"+ str(num_snapshot) + '.pth')\n",
    "      # 重置优化器，以及退火学习\n",
    "      optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "      lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "      num_snapshot += 1\n",
    "      lowest_loss = 10000\n",
    "\n",
    "    print('epoch: {} train_loss: {:.4f} val_loss: {:.4f}  lr: {:.4f}'.format(epoch_ + 1, train_loss*100, val_loss*100, lr_scheduler.get_last_lr()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch 保存参数\n",
    "\n",
    "|操作|函数|\n",
    "|-|-|\n",
    "|保存|torch.save(model.state_dict(),path)|\n",
    "|读取|torch.load(path)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6e7463ab38ffa65d2678dd98ae9d6c9783a580bfd91baaccc455120c17d4d4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
